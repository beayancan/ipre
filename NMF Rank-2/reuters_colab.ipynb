{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FOnO1SD-pzs"
   },
   "source": [
    "# NMF Rank-2 con dataset Reuters\n",
    "\n",
    "Autor: Benjamin Ayancán, PUC Chile\n",
    "Tutor: Denis Parra, PUC Chile\n",
    "\n",
    "En el siguiente notebook desarrollaremos un ejemplo de cómo poder generar una descomposición jerarquica a través del algoritmo de rango bajo NMF rank-2.\n",
    "\n",
    "* Para este tutorial usaremos el dataset de noticias Reuters que nos entrega la libería `keras`\n",
    "\n",
    "* Los aspectos teoricos y detalles del algoritmo son abordados en el  siguiente [notebook de Observablehq](https://observablehq.com/@beayancan/descomposicion-jerarquica)\n",
    "\n",
    "* Para hacer más pedagógico el ejemplo se va a reducir tanto la cantidad de datos (filas) como la cantidad de features (columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLET-ev4s9Rp"
   },
   "source": [
    "---\n",
    "\n",
    "## Configuración\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "--> Si lo estás ejecutando en un `jupyter notebook` debes instalar las siguientes librerías\n",
    "\n",
    "```py\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "```\n",
    "\n",
    "--> Si lo estás ejecutando en `colab`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEb5CzWsY-xO"
   },
   "outputs": [],
   "source": [
    "# Chequeamos que nuestro soporte no tenga problemas\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hb3X252TY0H2",
    "outputId": "1bb6d096-4898-4c6d-995a-462ac45e6fc1"
   },
   "outputs": [],
   "source": [
    "# importamos las liberías que vamos a utilizar\n",
    "# herramientas y el dataset\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import keras\n",
    "import statistics\n",
    "import collections\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPD06Xvdtbp7"
   },
   "source": [
    "---\n",
    "\n",
    "## Reuters\n",
    "\n",
    "#### ¿Por qué usar esta librería?\n",
    "\n",
    "Reuters es un repositorio de documentos que podemos utilizar a través de `keras` o bien descargarlo en su [página web](http://konect.cc/networks/gottron-reuters/). Esta posee las siguientes características\n",
    "\n",
    "* Son un conjunto de 11.228 noticias, etiquetados en 46 tópicos.\n",
    "\n",
    "\n",
    "* Está preprocesado según un ranking de palabras de un volabulario, es decir su representación es a través de las posiciones en el ranking de las palabras de un documento\n",
    "* Posee funciones sencillas que nos ayudan a manejar cómo representar los documentos sin gastar mucho tiempo en su preprocesamiento\n",
    "* Se enfoca en el contenido de un documento, las palabras que lo representan, en vez del mensaje que este entregue\n",
    "\n",
    "---\n",
    "\n",
    "#### Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBBfF4DIuHC-"
   },
   "outputs": [],
   "source": [
    "# PARAMETROS\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters/load_data\n",
    "\n",
    "# Cantidad de palabras significativas del vocabulario a usar\n",
    "\n",
    "# num_words = None # incluirlas todas\n",
    "num_words = 200 # solo tomaremos las 100 primeras palabras\n",
    "skip_top = 75 # palabras que no consideraremos\n",
    "\n",
    "# máximo N° de palabras para representar a un documento\n",
    "max_len = None # todas\n",
    "# max_len = 50\n",
    "\n",
    "# Porcentaje de palabras para usar en el test set\n",
    "test_split = 0.4 # train set: 97.5%, test set: 2.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MPNg4lWueWs9",
    "outputId": "cb6c810e-43e2-49e0-9614-3cee8e1a852c"
   },
   "outputs": [],
   "source": [
    "# Cargamos los de datos de clasificación de noticias de Reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words,\n",
    "                                                         maxlen=max_len,\n",
    "                                                         test_split=test_split,\n",
    "                                                         skip_top=skip_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "xrzJdAjwWnvA",
    "outputId": "cf86be6d-256b-4a1c-95f6-8143ea984288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train set: (6736,)\n",
      "Tamaño test set: (4492,)\n",
      "Cantidad clases: 46\n"
     ]
    }
   ],
   "source": [
    "# Revisamos cómo fueron cargados los datos\n",
    "\n",
    "# y_train, y_test contendrán los labels de las clases\n",
    "\n",
    "num_clases = max(y_train) + 1\n",
    "\n",
    "print(f'Tamaño train set: {x_train.shape}')\n",
    "print(f'Tamaño test set: {x_test.shape}')\n",
    "print(f'Cantidad clases: {num_clases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tW0E5KIwiCi"
   },
   "source": [
    "### Qué es lo que contienen\n",
    "* Cada elemento del set contiene los índices de las palabras más utilizadas por un documento\n",
    "\n",
    "* Las palabras están ordenadas según su frecuencia de aparición\n",
    "* Además cada documento pertenece a un tópico en especifico\n",
    "* Notar por el `x_train.shape` que las representaciones no tienen un largo especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "2SqXKHd1gxs8",
    "outputId": "c23a4019-c6e0-43ef-e894-2c6e51c8eaf7"
   },
   "outputs": [],
   "source": [
    "# Mostremos algunos ejemplos\n",
    "# for i in range(1,15, 3):\n",
    "#   print(f'Doc: {i},  largo: {len(x_test[i])}, clase {y_test[i]}')\n",
    "#   print(f'   contenido: {x_test[i]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "colab_type": "code",
    "id": "TmYUZB3gtZBd",
    "outputId": "f60e3dcb-7302-4b79-fc36-f6a169c9616c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Las clases y sus estadísticas\n",
      "Idx  Clase                train  test  Palabras\n",
      "    0 cocoa                   41    26   227.10\n",
      "    1 grain                  331   206   184.57\n",
      "    2 veg-oil                 53    41   189.55\n",
      "    3 earn                  2379  1593    89.53\n",
      "    4 acq                   1441   982   137.61\n",
      "    5 wheat                   11    11   215.82\n",
      "    6 copper                  33    29   153.64\n",
      "    7 housing                 14     5   196.00\n",
      "    8 money-supply           108    69   190.17\n",
      "    9 coffee                  81    45   220.44\n",
      "   10 sugar                   94    60   199.59\n",
      "   11 trade                  295   178   257.92\n",
      "   12 reserves                37    25   170.32\n",
      "   13 ship                   129    80   166.84\n",
      "   14 cotton                  17    11   154.47\n",
      "   15 carcass                 16    13   182.12\n",
      "   16 crude                  317   226   217.26\n",
      "   17 nat-gas                 29    22   148.07\n",
      "   18 cpi                     54    32   150.19\n",
      "   19 money-fx               414   268   188.41\n",
      "   20 interest               202   137   198.63\n",
      "   21 gnp                     78    49   272.90\n",
      "   22 meal-feed               10    12   178.30\n",
      "   23 alum                    34    19   165.32\n",
      "   24 oilseed                 48    33   159.65\n",
      "   25 gold                    63    60   153.41\n",
      "   26 tin                     15    17   224.33\n",
      "   27 strategic-metal         12     7   136.00\n",
      "   28 livestock               41    17   178.63\n",
      "   29 retail                  16     7   287.62\n",
      "   30 ipi                     31    26   174.52\n",
      "   31 iron-steel              30    22   147.60\n",
      "   32 rubber                  28    14   205.68\n",
      "   33 heat                     9     7   129.00\n",
      "   34 jobs                    36    21   144.53\n",
      "   35 lei                     10     6   142.30\n",
      "   36 bop                     39    21   224.21\n",
      "   37 zinc                    13     8   181.69\n",
      "   38 orange                  13     9   121.54\n",
      "   39 pet-chem                19    10   165.79\n",
      "   40 dlr                     27    19   286.59\n",
      "   41 gas                     23    15   192.39\n",
      "   42 silver                   8     8   151.25\n",
      "   43 wpi                     15    12   132.67\n",
      "   44 hog                     10     7    84.70\n",
      "   45 lead                    12     7   143.17\n"
     ]
    }
   ],
   "source": [
    "mapping = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "           'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "           'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "           'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "           'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']\n",
    "\n",
    "train_count = collections.Counter(y_train)\n",
    "test_count = collections.Counter(y_test)\n",
    "total_words = [statistics.mean([len(e) for e in x_train[y_train.flatten() == i]]) for i in range(46)]\n",
    "\n",
    "print(\"         Las clases y sus estadísticas\")\n",
    "print(\"{:4s} {:20s} {:5s}  {:5s} {:7s}\".format(\"Idx\",\"Clase\", \"train\", \"test\", \"Palabras\"))\n",
    "for i in range(46):\n",
    "   print(\"{:5d} {:20s} {:5d} {:5d}   {:6.2f}\".format(i,mapping[i], train_count[i], test_count[i], total_words[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1QfRta5-2UO"
   },
   "source": [
    "### Qué es lo que representan\n",
    "* Solo tenemos los índices, pero ¿de qué?\n",
    "  * Son la posición rankeada de la palabra\n",
    "* Usamos la indexación del vocabulario del dataset para identificar la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Ses2uu-X6EiC",
    "outputId": "6579106d-530b-4ea8-ff0e-ef9581941f4f"
   },
   "outputs": [],
   "source": [
    "# Tenemos el vocabulario con las palabras y sus indices\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# Generamos un diccionario con el contenido\n",
    "index_to_word = { value+3 : key for key, value in word_index.items() }\n",
    "\n",
    "# Indices reservados\n",
    "index_to_word[0] = '-PAD-'   # 0: carpeta\n",
    "index_to_word[1] = '-START-' # 1: inicio secuencia\n",
    "index_to_word[2] = '-UNK-'   # 2: elemento no encontrado\n",
    "\n",
    "len_index = len(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtkSV7UNPdc9"
   },
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "* Para poder realizar los calculos, necesitamos\n",
    "  * Una estructura regular de datos\n",
    "  * Que cada documento posea un mismo largo\n",
    "\n",
    "* Pasaremos primero los datos a una menor dimensión reduciendo las palabras y eliminando lo innecesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjKzIVgY2M2U"
   },
   "outputs": [],
   "source": [
    "# Primero eliminaremos las referencias a elementos que no se encuentran\n",
    "# dentro de las 1000 palabras más usadas en el vocabulario\n",
    "# ademas de las entradas reservadas\n",
    "\n",
    "  # Eliminamos\n",
    "  # 0: '-PAD-'\n",
    "  # 1: '-START-'\n",
    "  # 2: '-UNK-'\n",
    "  # 12: '3'\n",
    "  # 17: 'reuter'\n",
    "\n",
    "def filtrar_relevante(arreglo, por_eliminar=[0,1,2]):\n",
    "  \"\"\"\n",
    "  Borra las palabras que pertenecen a los indices del array por_eliminar\n",
    "  \"\"\"\n",
    "  return list(filter(lambda x: x not in por_eliminar, arreglo))\n",
    "\n",
    "def eliminar_reservadas(x_array):\n",
    "  \"\"\"\n",
    "  Eliminamos las entradas reservadas y entradas inutiles\n",
    "  retorna el contenido homogeneo del doc\n",
    "  \"\"\"\n",
    "  por_eliminar = [0,1,2,12,17]\n",
    "  largo_test, = x_array.shape\n",
    "  for i in range(largo_test):\n",
    "    x_array[i] = filtrar_relevante(x_array[i], por_eliminar)\n",
    "  return x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVifRE33sxqN"
   },
   "outputs": [],
   "source": [
    "# Para hacer un ejemplo más sencillo de entender\n",
    "# Selecionaremos solo las primeras 7 clases\n",
    "\n",
    "def conteo_labels(n, p):\n",
    "  return list( [0, randrange(p-3, p+3)] for _ in range(n) )\n",
    "\n",
    "def reducir_labels(data_array, labels, k=9, pivote=25):\n",
    "  \"\"\"\n",
    "  Filtramos los documentos que pertenezcan a las primeras k clases\n",
    "  Retornamos el arreglo con los documentos y sus correspondientes labels\n",
    "  \"\"\"\n",
    "  \n",
    "  conteo = conteo_labels(max(labels), pivote)\n",
    "  retorno, retorno_labels = list(), list()\n",
    "  for i in range(len(data_array)):\n",
    "    if labels[i] < k and conteo[labels[i]][0] < conteo[labels[i]][1]:\n",
    "      retorno.append(data_array[i])\n",
    "      retorno_labels.append(labels[i])\n",
    "      conteo[labels[i]][0] += 1\n",
    "  return np.array(retorno), retorno_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5NPalNU7tAXU",
    "outputId": "68f3ec51-ac70-4414-d91a-ae128e5848f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "x_test = eliminar_reservadas(x_test)\n",
    "x_data, y_data = reducir_labels(x_test, y_test, k=7, pivote=25)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "MbLfYLj3vI2m",
    "outputId": "f4b03fcf-6dea-4458-e898-871d68b0ea4d"
   },
   "outputs": [],
   "source": [
    "# Mostremos lo que contiene\n",
    "for i in range(1,15, 3):\n",
    "  #print(f'Doc: {i},  Largo: {len(x_data[i])}, Clase {y_data[i]}')\n",
    "  #print(f' {x_data[i]}', '\\n', ' '.join([index_to_word[word] for word in x_data[i]]), \"\\n\")\n",
    "  continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VV9CKo3L8Get"
   },
   "source": [
    "### Pasar los datos a matriz doc-term\n",
    "\n",
    "* Pasamos a una matriz $A \\in \\mathbb{R}^{m \\times n}$ donde $m$ es la cantidad de documentos y $n$ es la cantidad de palabras del vocabulario\n",
    "* Pasaremos los datos a una representación de $\\{0, 1\\}$\n",
    "* Representando la entrada $A[i,j]$ la aparición en el $i$-ésimo documento la $j$-ésima palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ngXLKqz6etw"
   },
   "outputs": [],
   "source": [
    "# Importamos tokenizer para producirlo\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tkn = Tokenizer(num_words=num_words) # tamaño del vocabulario\n",
    "num_clases = max(y_data) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2pvAU85QIr6"
   },
   "outputs": [],
   "source": [
    "# Contruimos la matriz pasando los datos a binario\n",
    "\n",
    "x_data_bin = tkn.sequences_to_matrix(x_data, mode='binary')\n",
    "y_data_cat = to_categorical(y_data, num_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "mVCpasedQepb",
    "outputId": "568305d5-dfb3-4f3b-aa4c-6ff3dac0b70c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: (159, 200) \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "\n",
      "Test Set: (159, 7)   (usaremos este) \n",
      " [0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los como queda la representacion\n",
    "\n",
    "entry = 10\n",
    "print(f'Train Set: {x_data_bin.shape} \\n {x_data_bin[entry]}\\n')\n",
    "print(f'Test Set: {y_data_cat.shape}   (usaremos este) \\n {y_data_cat[entry]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox3JNVrwQc2o"
   },
   "outputs": [],
   "source": [
    "# Siguiendo la interpretación del paper\n",
    "\n",
    "A_matrix = np.transpose(x_data_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTEMF7ZhSrYl"
   },
   "source": [
    "# NMF Jerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aa4N91wyStwu"
   },
   "source": [
    "* Ya tenemos unos datos preprocesados de forma ideal para nuestro trabajo\n",
    "* Realizaremos la secuencia de NMF jerárquico siguiendo el paper\n",
    "  * [Fast Rank-2 Nonnegative Matrix Factorization for Hierarchical Document Clustering](https://smallk.github.io/papers/hierNMF2.pdf)\n",
    "\n",
    "* Recordar que el objetivo es minimizar la siguiente operación\n",
    "  $$\\min_{W \\geq 0, H \\geq 0} ||A - WH||_2^{2}$$\n",
    "\n",
    "* Dado que corresponde a un problema no convexo, dividimos la resolución en **dos poblemas convexos**\n",
    "$$\\min_{H \\geq 0} ||A - WH||_2^{2}$$\n",
    "$$\\min_{W \\geq 0} ||A^T - H^T W^T||_2^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Rank-2\n",
    "\n",
    "* Usaremos el algoritmo NNSL para generar una estructura de árbol binario jerárquico\n",
    "\n",
    "* Una factorización de este tipo es de \"mala calidad\", pues no se obtiene una buena aproximación de la matriz factorizada. Sin embargo, la eficiencia del algoritmo consigue realizar la operación de forma rápida y sencilla.\n",
    "\n",
    "* Utilizaremos el punto anterior para desarrollar la aproximación de **NMF Rank-2** de **forma recursiva** sobre la matriz para generar una solución adecuada y más interpretativa debido a su estructura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NcwIIZe32N7"
   },
   "source": [
    "### Algoritmo Genérico NNSL\n",
    "\n",
    "Sea una matriz $A \\in \\mathbb{R}^{m \\times n}$ compuesta por multiples columnas $[a_1, a_2, \\ldots, a_n]$, con  $a_i \\in \\mathbb{R}^{m}$ independientes entre sí (supuesto), tenemos que es posible iterar de la siguiente manera para encontrar la matriz incognita derecha $X \\in \\mathbb{R}^{2 \\times n}$ dado que conocemos la matriz izquierda $B \\in \\mathbb{R}^{m \\times 2}$.\n",
    "\n",
    "#### Input:\n",
    "Recibimimos la matriz a factorizar $A$ junto a su ya conocida matriz izquierda de la factorización (supuesto)\n",
    "\n",
    "* $A \\in \\mathbb{R}^{m \\times n}, \\qquad B = [b_1, b_2] \\in \\mathbb{R}^{m \\times 2}$\n",
    "\n",
    "#### Output:\n",
    "Obtenemos la matriz derecha que minimiza la siguiente ecuación\n",
    "\n",
    "* $X = \\text{argmin}_{X \\geq 0} ||BX - A||^2_2$\n",
    "\n",
    "#### Pasos\n",
    "\n",
    "* Resolvemos mínimos cuadrados $ \\quad X = \\text{argmin}_{X} ||BX - A|| \\in \\mathbb{R}^{2 \\times n}$\n",
    "\n",
    "\n",
    "* Es necesario asegurarnos de que la matriz será positiva\n",
    "\n",
    "* Por lo que calculamos\n",
    "\n",
    "    * $\\quad u = \\dfrac{<A^T, b_1>}{||b_1||^2} \\in \\mathbb{R}, \\qquad v = \\dfrac{<A^T, b_2>}{||b_2||^2} \\in \\mathbb{R}$\n",
    "\n",
    "\n",
    "* for $j=1$ to $n$:\n",
    "  * if $\\quad X_j \\geq 0 \\quad \\Longrightarrow \\quad $ continue\n",
    "  * else:\n",
    "    * if $\\quad u_1 ||b_1|| \\geq v_j ||b_2|| \\quad \\Longrightarrow \\quad X_j = [u_j, \\, 0]^T$\n",
    "    * else: $\\quad \\Longrightarrow \\quad X_j = [0, \\, v_j]^T$\n",
    "    \n",
    "    \n",
    "* return $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código NNSL\n",
    "\n",
    "A través del algoritmo anterior, es posible resolver la ecuación convexa\n",
    "\n",
    "$$\\text{min}_{X \\geq 0} ||BX - Y||^2_2$$\n",
    "\n",
    "Partimos realizando el código del algoritmo recien visto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9slMc7UPuZPW"
   },
   "outputs": [],
   "source": [
    "def rank2(A, W):\n",
    "  \"\"\"\n",
    "  Recibe las matrices objetivo A y su matriz izquierda W\n",
    "  Calcula la resolución iterativa de la minimización según el paper\n",
    "  y obtenemos la minimización de H a partir de W\n",
    "  Retorna las matrices W, H de las descomposición\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A)\n",
    "\n",
    "  # resolvemos por minimos cuadrados\n",
    "  H = np.linalg.solve(np.dot(np.transpose(W), W), np.dot(np.transpose(W), A))\n",
    "\n",
    "  # Separamos en columnas\n",
    "  w1, w2 = W[:, 0], W[:, 1]\n",
    "  beta1, beta2 = np.linalg.norm(w1), np.linalg.norm(w2)\n",
    "\n",
    "  # normalizamos\n",
    "  u, v = np.dot(np.transpose(A), w1)/beta1, np.dot(np.transpose(A), w2)/beta2\n",
    "\n",
    "  for j in range(n):\n",
    "    # Para cada vector determinamos si cumple con la solucion\n",
    "    retorno_j = np.zeros(2)\n",
    "    if (H[:, j] >= 0).all():\n",
    "      continue\n",
    "    elif u[j]*beta1 >= v[j]*beta2:\n",
    "      retorno_j[0] = u[j]\n",
    "    else:\n",
    "      retorno_j[1] = v[j]\n",
    "    H[:, j] = retorno_j\n",
    "  return W, H\n",
    "\n",
    "def NMF_rank2(A, W=None, H=None, k=2, **kwargs):\n",
    "  \"\"\"\n",
    "  Recibe la matriz objetivo y matrices iniciales\n",
    "  Se realiza dos veces la minimización primero para H\n",
    "  y luego para W\n",
    "  Retorna la descomposición W, H de baja calidad\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A)\n",
    "\n",
    "  # Iniciamos las matrices\n",
    "  if W is None:\n",
    "    W = np.random.rand(m, k)\n",
    "\n",
    "  if H is None:\n",
    "    H = np.zeros((k, n))\n",
    "  \n",
    "  # Realizamos las minimizaciones\n",
    "  W, H = rank2(A, W)\n",
    "  HT, WT = rank2(np.transpose(A), np.transpose(H))\n",
    "  # Retornamos los valores que resultaron minimizados\n",
    "  return np.transpose(WT), np.transpose(HT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer el calculo de NMF rank-2 vamos a utilizar diversas iteraciones en una operacion recursiva que busque ir ajustando la solución de acuerdo al calculo anterior, cada iteración para NMF se guiará de la siguiente forma\n",
    "\n",
    "* Para resolver los problemas convexos planteados anteriormente resolveremos en torno a la matriz derecha $H$ del problema, ajustandola de acuerdo a la izquierda $W$ para aproximar el objetivo $A$ según el algoritmo NNSL\n",
    "\n",
    "$$\\min_{H \\geq 0} ||A - WH||_2^{2}$$\n",
    "\n",
    "* Tras esto, invertimos los papeles ajustando la matriz izquierda $W$ respecto de la matriz derecha $W$ usando el mismo algoritmo, esto lo conseguimos transponiendo las matrices ya que resuelven el mismo problema\n",
    "\n",
    "$$\\min_{W \\geq 0} ||A^T - H^T W^T||_2^{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu4Uze6DOUOW"
   },
   "outputs": [],
   "source": [
    "def calculo_NMF(A, max_iteraciones=15, k=2, W=None, H=None, error=0.5):\n",
    "  \"\"\"\n",
    "  Recibe la matriz objetivo A, dimension k,\n",
    "  máximo de iteraciones y matrices iniciales\n",
    "  Realiza de forma recursiva la aplicación de rank-2\n",
    "  para así obtener una mejor aproximación\n",
    "  Retorna los elementos W, H que aproximan A\n",
    "  al alcanzar una cota de error o superar el maximo\n",
    "  \"\"\"\n",
    "  # Inicializamos las matrices\n",
    "  m, n = np.shape(A)\n",
    "  if W is None:\n",
    "    W = np.random.rand(m, k)\n",
    "\n",
    "  for i in range(max_iteraciones):\n",
    "    W, H = rank2(A, W)\n",
    "    HT, WT = rank2(np.transpose(A), np.transpose(H))\n",
    "    W, H = np.transpose(WT), np.transpose(HT)\n",
    "    if (np.linalg.norm(A - np.dot(W, H))) < error: break\n",
    "  return W, H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para alcanzar la representación que busca el algoritmo, tenemos que la matriz W debe ser la frecuencia de las palabras, por lo que pasamos a normalizar sus columnas\n",
    "* Del mismo modo ponderamos su fila respectiva en la matriz H para no perder representatividad\n",
    "\n",
    "* Además de eso, debido a que el calculo es con inicializacion de matrices random, es necesario realizar el calculo de la aproximación en diversas veces, pues puede ocurrir que minimos cuadrados no posea solucion al no ser una matriz diagonal dominante, por lo que hay que empezar denuevo.\n",
    "\n",
    "* Por medio de experimientos fue posible determinar que 15 es una cota adecuada de intentos a realizar con tal de conseguir finalmente la aproximacion que sea de buena mediada a la matriz objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2AEFL66POis"
   },
   "outputs": [],
   "source": [
    "def normalizar_descomposicion(W, H):\n",
    "  \"\"\"\n",
    "  Normaliza las columnas de W y pondera respectivamente\n",
    "  las filas de H para el resultado esperado\n",
    "  \"\"\"\n",
    "\n",
    "  for j in range(2):\n",
    "    norma = np.linalg.norm(W[:, j])\n",
    "    W[:, j] = W[:, j]/norma\n",
    "    H[j, :] = H[j, :]*norma\n",
    "  return W, H\n",
    "\n",
    "\n",
    "def calcular_descomposicion(A_matrix, max_iteraciones=15, max_intentos=10):\n",
    "  \"\"\"\n",
    "  Recibe matriz objetivo, cantidad maxima iteraciones e intentos de calcular\n",
    "  Calcula la descomposición rank-2 de forma reiterativa\n",
    "  Si el i-esimo intento alcanza la cota\n",
    "  se retorna la descomposición W, H\n",
    "  \"\"\"\n",
    "  salida, excepcion = False, False\n",
    "  for i in range(max_intentos):\n",
    "    try:\n",
    "      W, H = calculo_NMF(A_matrix, max_iteraciones, k=2, W=None, H=None)\n",
    "      error = np.linalg.norm(np.dot(W, H) - A_matrix)\n",
    "      if error < 60:\n",
    "        salida = True\n",
    "    except:\n",
    "      excepcion = True\n",
    "    else:\n",
    "      if not excepcion and salida:\n",
    "        return normalizar_descomposicion(W, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_t-3DmOnyv3"
   },
   "source": [
    "## Generar Estructura jerárquica\n",
    "\n",
    "Dado que ya tenemos lo suficiente para poder generar una factorización NMF de rango 2, vamos a definir **la forma de generar la estructura jerárquica de árbol binario**. Una idea general para esto es la siguiente\n",
    "\n",
    "* Tomar la matriz $A$ como nodo raiz\n",
    "* Realizar descomposición NMF rank-2 sobre ella obteniendo $W \\in \\mathbb{R}^{m \\times 2}$ y $H \\in \\mathbb{R}^{2 \\times n}$\n",
    "    * Donde $W$ serán dos largas columnas con la distribución de palabras\n",
    "    * Y $H$ serán dos largas filas con la distribución de documentos\n",
    "* Determinamos a través de las columnas de $W$ si la descomposición NMF entregó una buena separación\n",
    "    * Es necesario definir qué es una buena separación\n",
    "* En caso de que que sea una buena separación, dividimos (*split*) la matriz raiz en dos ramas $A_{1}$ y $A_{2}$ a partir de elementos de $W$ y $H$. Repitiendo posteriormente el paso sobre cada una.\n",
    "\n",
    "* O bien si no es una buena separación, olvidamos lo calculado y volvemos a empezar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensemos en formato árbol\n",
    "\n",
    "Para el algoritmo es necesario destacar que cada nodo del árbol jerárquico estará representado por una matriz $A_{i} \\in \\mathbb{m_i \\times n_i}$, el cómo es generado cada uno de estos nodos se mostrará en las siguientes celdas. Para hacer las divisiones usaremos la información de las palabras que se encuentra contenida en la matriz $W$ de cada nodo, aquí una guía de pasos.\n",
    "\n",
    "Si yo aplico NMF sobre $A$ y genero las matrices $W$ y $H$, al seleccionar solo ciertos elementos de $W$ y de $H$, digamosles $W'$ y $H'$, multiplicandolos puedo generar una matriz nueva y más pequeña $W' \\cdot H' = A'$. Y usando los elementos que no seleccioné antes y los agrupo como $W''$ y $H''$ también genero una matriz nueva más pequeña $W'' \\cdot H'' = A''$.\n",
    "\n",
    "La clave es que tanto $A'$ como $A''$ pueden llegar a ser diferentes (depende de cómo hayamos seleccionado) pero ambas contienen información de $A$.\n",
    "\n",
    "* El dividir y conquistar los datos nos permitirá realizar el algoritmo de forma recursiva para poder realizar esta selección de buena manera\n",
    "  * Aplicaremos NMF sobre A\n",
    "  * Revisaremos si vale la pena dividir\n",
    "  * Haremos split de los datos\n",
    "  * A estos dos hijos de datos les aplicaremos NMF\n",
    "  * Continuaremos hasta alcanzar cierto objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pensemos cómo hacer el árbol\n",
    "\n",
    "Denotaremos a $`\\mathcal{N}$ como **un nodo cualquiera del árbol binario**, cuyo corazón es una matriz $A \\in \\mathbb{m \\times n}$, de este nodo sabemos\n",
    "\n",
    "* La matriz izquierda $W$ de NMF rank-2 contiene dos columnas con la distribucion de palabras\n",
    "\n",
    "* Por lo anterior, $`\\mathcal{N}$ tiene asociado una distribución de palabras de una columna de alguna matriz $W$, ya sea $W[1] o W[2]$, que permitió crear este nodo\n",
    "\n",
    "* Denotaremos como $f_{\\mathcal{N}}$ a la lista de palabras asociadas a $\\mathcal{N}$ que se encuentran ordenadas según su frecuencia\n",
    "\n",
    "* Si aplicamos NMF sobre $A$, generaremos dos **posibles hijos** para el nodo $\\mathcal{N}$. De igual forma, estos hijos tendrán asociadas listas de palabras que llamaremos $f_{\\mathcal{L}}$ y $f_{\\mathcal{R}}$ por las columnas izquierda y derecha de la **posible** matriz $W$ de su NMF.\n",
    "\n",
    "    * Es necesario destacar el **posible** por lo que se mencionó en pasos anteriores, el ejecutar NMF no te asegura que los hijos sean los adecuados\n",
    "    \n",
    "    \n",
    "* A partir de estas listas de palabras generaremos una métrica que nos permitirá decidir si es conveniente o no dividir el nodo con estos hijos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVZ4E3og0I0E"
   },
   "outputs": [],
   "source": [
    "def idx_plbs(arreglo):\n",
    "  \"\"\"\n",
    "  Recibe un arreglo de palabras\n",
    "  Genera un diccionario con los detalles de la palabra\n",
    "  retornando una lista ordenada según relevancia\n",
    "  \"\"\"\n",
    "  largo = len(arreglo)\n",
    "  retorno = list({'word': i, 'value': arreglo[i]} for i in range(largo))\n",
    "  retorno = sorted(retorno, key=lambda x: x['value'], reverse=True)\n",
    "\n",
    "  for i in range(largo):\n",
    "    retorno[i]['id'] = i\n",
    "  return retorno\n",
    "\n",
    "def generar_arrays(array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos para poder dividir\n",
    "  Retorna los arreglos ordenados según relevancia de sus palabras\n",
    "  \"\"\"\n",
    "  return idx_plbs(array_N), idx_plbs(array_L), idx_plbs(array_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ya tenemos los arreglos de las palabras ordenados\n",
    "* Es necesario definir una métrica para saber si los arreglos nos permiten separar de forma exitosa\n",
    "* En nuestro caso vamos a utilizar el **modified Normalized Discounted Cumulative Gain** o bien **mNDCG**\n",
    "\n",
    "* Este nos permite decidir qué tan bien mantienen la frecuencia los arreglos $\\mathcal{L}$ y $\\mathcal{R}$ respecto de su nodo padre $\\mathcal{N}$, es decir, si ganamos información nueva en caso de separar de esta forma\n",
    "\n",
    "    * Piensa en cómo separas una canasta con muchas frutas en dos canastas, si quieres clasificarlas ¿Vas a colocar frutas de los mismos tipos en la misma proporción en las canastas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iVS2CBb3-YI"
   },
   "outputs": [],
   "source": [
    "def factor_descuento(word, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos y la palabra para la cual\n",
    "  se va a calcular su descuento\n",
    "  Retorna el descuento de la palabra\n",
    "  \"\"\"\n",
    "\n",
    "  fi_L = next(x for x in array_L if x['word'] == word)\n",
    "  fi_R = next(x for x in array_R if x['word'] == word)  \n",
    "  return np.log2(len(array_L) - max(fi_L['id'], fi_R['id']) + 1)\n",
    "\n",
    "\n",
    "def ganancia_palabra(word, array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos y la palabra de la que se quiere obtener su ganancia\n",
    "  Retorna la ganancia de la palabra\n",
    "  \"\"\"\n",
    "  \n",
    "  descuento = factor_descuento(word, array_L, array_R)\n",
    "  elemento = next(x for x in array_N if x['word'] == word)\n",
    "  return np.log2(len(array_L) - elemento['id'] + 1)/descuento\n",
    "\n",
    "\n",
    "def ganancias(array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Calcula la ganancia del arreglo\n",
    "  Retorna el arreglo de las ganancias y ordenada según ganancia\n",
    "  \"\"\"\n",
    "  retorno = list()\n",
    "  for word in range(len(array_N)):\n",
    "    gan_actual = ganancia_palabra(word, array_N, array_L, array_R)\n",
    "    retorno.append({'palabra': word, 'ganancia': gan_actual})\n",
    "  \n",
    "  return retorno, sorted(retorno, key=lambda x: x['ganancia'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkS5BLqhGJuf"
   },
   "outputs": [],
   "source": [
    "def MDCG(gan_array):\n",
    "  \"\"\"\n",
    "  Calculo de MDCG según el array que se entregue\n",
    "  Retorna el valor de ganancia\n",
    "  \"\"\"\n",
    "  largo = len(gan_array)\n",
    "  elementos = list(gan_array[i]['ganancia']/np.log2(i+1) for i in range(1, largo))\n",
    "  return gan_array[0]['ganancia'] + sum(elementos)\n",
    "\n",
    "\n",
    "def mNDCG(gan_array, gan_sort):\n",
    "  \"\"\"\n",
    "  Calculo del puntaje a través de los arrays listos\n",
    "  \"\"\"\n",
    "  return MDCG(gan_array)/MDCG(gan_sort)\n",
    "\n",
    "\n",
    "def puntaje(f_N, f_L, f_R):\n",
    "  \"\"\"\n",
    "  Calcula el puntaje de la descomposición NMF actual\n",
    "  Retorna el valor que nos ayuda a decidir\n",
    "  \"\"\"\n",
    "  gan, gan_sort = ganancias(*generar_arrays(f_N, f_L, f_R))\n",
    "  return mNDCG(gan, gan_sort)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42-U4DSMNT_b"
   },
   "outputs": [],
   "source": [
    "def elem_puntaje(A_matrix, L_matrix, R_matrix):\n",
    "  \"\"\"\n",
    "  Calcula la descomposición NMF de A (nodo)\n",
    "  y de sus posibles hijos\n",
    "  Retorna los elementos necesarios para determinar si conviene\n",
    "  \"\"\"\n",
    "\n",
    "  condicion = False\n",
    "  while not condicion:\n",
    "    try:\n",
    "      W, H = calcular_descomposicion(A_matrix)\n",
    "      WL, HL = calcular_descomposicion(L_matrix)\n",
    "      WR, HR = calcular_descomposicion(R_matrix)\n",
    "      condicion = True\n",
    "    except:\n",
    "      condicion = False\n",
    "    else:\n",
    "      if condicion:\n",
    "        return W, H, WL, HL, WR, HR\n",
    "\n",
    "def calculo_puntajes(W, H, WL, HL, WR, HR, i):  \n",
    "  \"\"\"\n",
    "  Calcula el puntaje de los hijos del nodo\n",
    "  a partir de los \n",
    "  \"\"\"\n",
    "  X = W[:, i].copy()\n",
    "\n",
    "  puntaje_N1 = puntaje(X, WL[:, 0], WL[:, 1])\n",
    "  puntaje_N2 = puntaje(X, WR[:, 0], WR[:, 1])\n",
    "\n",
    "  return puntaje_N1, puntaje_N2\n",
    "\n",
    "\n",
    "def puntajes_hijos(A, L, R):\n",
    "  \"\"\"\n",
    "  Genera el calculo del puntaje a partir de los\n",
    "  elementos necesario a partir del nodo\n",
    "  \"\"\"\n",
    "  # W, H, WL, HL, WR, HR = elem_puntaje(A, L, R)\n",
    "  return calculo_puntajes(*elem_puntaje(A, L, R), 0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjhkLjQoaOVE"
   },
   "outputs": [],
   "source": [
    "def agregar_columna(A, columna):\n",
    "  \"\"\"\n",
    "  Agrega columna a la matriz A sin importar su contenido\n",
    "  Retorna la matriz con la columna añadida\n",
    "  \"\"\"\n",
    "  if A is None:\n",
    "    A = np.zeros((len(columna), 1))\n",
    "    A[:, 0] = columna\n",
    "  else:\n",
    "    A = np.column_stack((A,columna))\n",
    "  return A\n",
    "\n",
    "\n",
    "def split_matrix(A_matrix, W, H, columnas):\n",
    "  \"\"\"\n",
    "  Separación de la matriz por contenido\n",
    "  Retorna la separación en dos matrices\n",
    "  \n",
    "  col_docs:\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A_matrix)\n",
    "\n",
    "  A1, A2 = None, None\n",
    "  \n",
    "  retorno_A1 = list()\n",
    "  retorno_A2 = list()\n",
    "\n",
    "  for j in range(n):\n",
    "    if H[0][j] > H [1][j]:\n",
    "      A1 = agregar_columna(A1, A_matrix[:, j])\n",
    "      retorno_A1.append(columnas[j])\n",
    "    else:\n",
    "      A2 = agregar_columna(A2, A_matrix[:, j])\n",
    "      retorno_A2.append(columnas[j])\n",
    "\n",
    "  if A1.shape[1] >= A2.shape[1]:\n",
    "    return A1, A2, retorno_A1, retorno_A2\n",
    "  return A2, A1, retorno_A2, retorno_A1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhzFR8xYf5fq"
   },
   "source": [
    "# Parte final\n",
    "\n",
    "Vamos a generar un arreglo que contenga la estructura de nuestro arbol\n",
    "* Será un ejemplo sencillo por lo que usaremos pocos nodos\n",
    "* Usamos un arreglo para los nodos generado\n",
    "* Retornaría este arreglo que describe la estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fbk-HUhf4-I"
   },
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "\n",
    "numero_nodos = 7 # cantidad nodos para crear\n",
    "beta = 1.1 # diferencia de tamaño mínima que habrá entre los nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdxgV1Pf1S3p"
   },
   "outputs": [],
   "source": [
    "def palabras_columna(W, i):\n",
    "  \"\"\"\n",
    "  Genera el arreglo de las palabras de la columna i\n",
    "  Retorna arreglo diccionarios con los datos ordenados\n",
    "  \"\"\"\n",
    "\n",
    "  entradas = ['idx', 'value']\n",
    "  distribucion, retorno = W[:, i], list()\n",
    "  for item in enumerate(distribucion):\n",
    "    retorno.append(dict(zip(entradas, item)))\n",
    "  return sorted(retorno, key=lambda i: i['value'], reverse=True)\n",
    "\n",
    "\n",
    "def encontrar_significado(arreglo):\n",
    "  \"\"\"\n",
    "  Recibe el arreglo de indices de palabras\n",
    "  Retorna los elementos con atributo word que es el significado\n",
    "  \"\"\"\n",
    "  for i in range(len(arreglo)):\n",
    "    arreglo[i]['word'] = index_to_word[arreglo[i]['idx'] + 4]\n",
    "  return arreglo\n",
    "\n",
    "def eliminar_numeros(arreglo):\n",
    "  numeros = [str(i) for i in range(10)]\n",
    "  retorno = list()\n",
    "  for palabra in arreglo:\n",
    "    if palabra['word'][0] in numeros:\n",
    "      continue\n",
    "    retorno.append(palabra)\n",
    "  return retorno\n",
    "\n",
    "def palabras_destacadas(W, cantidad=3):\n",
    "  \"\"\"\n",
    "  Selecciona las palabras más relevantes\n",
    "  de la matriz W\n",
    "  Retorna un arreglo con astas palabras\n",
    "  \"\"\"\n",
    "  n = int(np.round(cantidad/2))+1\n",
    "  retorno = encontrar_significado(palabras_columna(W, 0)[:n])\n",
    "  retorno = eliminar_numeros(retorno)\n",
    "  retorno_2 = encontrar_significado(palabras_columna(W, 1)[:n])\n",
    "  retorno_2 = eliminar_numeros(retorno_2)\n",
    "  retorno.extend(retorno_2)\n",
    "  return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUj8shzZ9B9J"
   },
   "outputs": [],
   "source": [
    "def obtener_palabras_destacadas(lista_arbol, cantidad=10):\n",
    "  for nodo in lista_arbol:\n",
    "    if nodo['matrix'].shape[1] == 1:\n",
    "      nodo['W'] = nodo['matrix']\n",
    "    elif 'W' not in nodo.keys():\n",
    "      nodo['W'], nodo['H'] = calcular_descomposicion(nodo['matrix'])\n",
    "    nodo['destacadas'] = palabras_destacadas(nodo['W'], cantidad)\n",
    "    #nodo['destacadas'] = palabras_relevantes(nodo['destacadas'])\n",
    "  return lista_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJgG4CuvgyXS"
   },
   "outputs": [],
   "source": [
    "def seleccionar_nodo(lista_nodos):\n",
    "  \"\"\"\n",
    "  Recibe el arreglo de los nodos de la estructura\n",
    "  Calcula cual nodo es conveniente separar y lo retorna\n",
    "  \"\"\"\n",
    "  if len(lista_nodos) == 1:\n",
    "    return lista_nodos[0]\n",
    "  #lista_nodos = sorted(lista_nodos, key = lambda i: i['id'], reverse=False)\n",
    "  lista_nodos = sorted(lista_nodos, key = lambda i: i['puntaje'], reverse=True)\n",
    "  for elemento in lista_nodos:\n",
    "    if elemento['hijos'] is None:\n",
    "      return elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQzkWiA8f2yg"
   },
   "outputs": [],
   "source": [
    "def jerarquizacion(A_matrix):\n",
    "  \"\"\"\n",
    "  Genera la estructura de jerarquía realizando\n",
    "  descomposiciones NMF de forma recursiva\n",
    "  Retorna la estructura \n",
    "  \"\"\"\n",
    "\n",
    "  outliner = None\n",
    "  lista_nodos = list()\n",
    "\n",
    "  primer_nodo = {\n",
    "    'id': 1,\n",
    "    'parent': None,\n",
    "    'matrix': A_matrix,\n",
    "    'puntaje': 1,\n",
    "    'shape': A_matrix.shape,\n",
    "    'columnas': list(i for i in range(A_matrix.shape[1]))\n",
    "  }\n",
    "\n",
    "  lista_nodos.append(primer_nodo)\n",
    "\n",
    "  for i in range(1, numero_nodos, 2):\n",
    "    M = seleccionar_nodo(lista_nodos)\n",
    "    M['W'], M['H'] = calcular_descomposicion(M['matrix'])\n",
    "    #M['W'], M['H'] = W, H\n",
    "    \n",
    "    N1, N2, cols_N1, cols_N2 = split_matrix(M['matrix'],\n",
    "                                            M['W'],\n",
    "                                            M['H'],\n",
    "                                            M['columnas'])\n",
    "    \n",
    "    puntaje_N1, puntaje_N2 = puntajes_hijos(M['matrix'], N1, N2)\n",
    "    \n",
    "    N1_nodo = {\n",
    "    'id': i+1,\n",
    "    'parent': M['id'],\n",
    "    'matrix': N1,\n",
    "    'puntaje': puntaje_N1,\n",
    "    'shape': N1.shape,\n",
    "    'hijos': None,\n",
    "    'columnas': cols_N1\n",
    "    }\n",
    "\n",
    "    N2_nodo = {\n",
    "    'id': i+2,\n",
    "    'parent': M['id'],\n",
    "    'matrix': N2,\n",
    "    'puntaje': puntaje_N2,\n",
    "    'shape': N2.shape,\n",
    "    'hijos': None,\n",
    "    'columnas': cols_N2\n",
    "    }\n",
    "\n",
    "    M['hijos'] = [i+1, i+2, ]\n",
    "\n",
    "    lista_nodos.append(N1_nodo)\n",
    "    lista_nodos.append(N2_nodo)\n",
    "\n",
    "  return obtener_palabras_destacadas(lista_nodos, cantidad=10)\n",
    "  #return lista_nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IPf2qvqkVBtc",
    "outputId": "75ee4779-3c94-44ca-9517-42be9ffb01e2"
   },
   "outputs": [],
   "source": [
    "def matriz_W_lista(lista_nodos):\n",
    "  for nodo in lista_nodos:\n",
    "    if 'W' not in nodo.keys():\n",
    "      nodo['W'], nodo['H'] = calcular_descomposicion(nodo['matrix'])\n",
    "  return lista_nodos\n",
    "\n",
    "\n",
    "def limpiar_lista(lista_nodos):\n",
    "  elementos = ['matrix', 'W', 'H']\n",
    "  new_list = [{k: v for k, v in d.items() if k not in elementos} for d in lista_nodos]\n",
    "  return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = jerarquizacion(A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = obtener_palabras_destacadas(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OiuTMnkiOfR"
   },
   "outputs": [],
   "source": [
    "#lista_arbol = limpiar_lista(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicos_relevantes(y_data, columnas, mapping):\n",
    "  counts = dict()\n",
    "  for col in columnas:\n",
    "    if str(y_data[col]) in counts:\n",
    "      counts[str(y_data[col])] += 1\n",
    "    else:\n",
    "      counts[str(y_data[col])] = 1\n",
    "      \n",
    "  keys = ['label', 'frequency']\n",
    "\n",
    "  auxiliar = list(dict(zip(keys, tupla)) for tupla in counts.items())\n",
    "\n",
    "  labels = sorted(auxiliar, key = lambda i: i['frequency'], reverse=True)\n",
    "  \n",
    "  for elemento in labels:\n",
    "    elemento['label'] = int(elemento['label'])\n",
    "    elemento['label_name'] = mapping[elemento['label']]\n",
    "  return labels[:3]\n",
    "\n",
    "def palabras_relevantes(palabras):\n",
    "  return list(x['word'] for x in palabras[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presentar_nodos(lista_arbol):\n",
    "  for objeto in lista_arbol:\n",
    "    print(f\"Nodo {objeto['id']}\")\n",
    "    print(f\"  parent: {objeto['parent']} - leafs {objeto['hijos']}\")\n",
    "    topicos = topicos_relevantes(y_data, objeto['columnas'], mapping)\n",
    "    for topico in topicos:\n",
    "      print(topico)\n",
    "    print(\"\")\n",
    "    palabras = palabras_relevantes(objeto['destacadas'])\n",
    "    frase = \"\"\n",
    "    for w in palabras:\n",
    "      if frase:\n",
    "        frase += \" / \"\n",
    "      frase += w\n",
    "    print(frase)\n",
    "    print(\"----------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = obtener_palabras_destacadas(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#presentar_nodos(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def top_words(palabras):\n",
    "  arreglo_palabras = dict((x['word'], x['value']) for x in palabras)\n",
    "  return dict(sorted(arreglo_palabras.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "def arreglar_destacadas(lista_nodos):\n",
    "  for nodo in lista_nodos:\n",
    "    nodo['destacadas'] = top_words(nodo['destacadas'])\n",
    "  return lista_nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = arreglar_destacadas(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_caracteristicas(lista_nodos, caracteristicas):\n",
    "  retorno = list()\n",
    "  for elemento in lista_nodos:\n",
    "    actual = dict()\n",
    "    for x in caracteristicas:\n",
    "      actual[x] = elemento[x]\n",
    "    retorno.append(actual)\n",
    "  return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_relevante = seleccionar_caracteristicas(lista_arbol, ['id', 'parent', 'hijos', 'destacadas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./reuters.json', 'w') as file:\n",
    "    json.dump(lista_relevante , file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reuters.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
