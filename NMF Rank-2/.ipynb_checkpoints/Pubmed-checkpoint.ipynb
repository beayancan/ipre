{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publimed estilo Reuters\n",
    "\n",
    "En el siguiente notebook vamos a utilizar el dataset publimed con el cual aplicaremos NMF, por lo que:\n",
    "* El dataset corresponde a una recopilación de preguntas médicas sobre documentos de diversos tópicos médicos\n",
    "* Vamos a pasar el dataset al estilo Reuters\n",
    "    * Recordar que esto se refiere a una representacion a través de las palabras y frecuencias\n",
    "* Utilzaremos sobre ella la descomposición NMF Rank-2\n",
    "    * Nos enfocaremos en una clasificación sobre los tópicos de los documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from IPython.display import display\n",
    "from graphviz import Digraph, nohtml\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de los datos\n",
    "\n",
    "* Convertiremos el dataset publimed que mantenemos almacenados en un documento CSV\n",
    "* Leeremos los documentos y rescataremos los datos que nos interesan\n",
    "* Codificaremos tanto su contenido como su etiqueta para dejarlo en formato \"Reuters\"\n",
    "    * Esta se refiere a una representacion a través de las palabras del doc\n",
    "    * La codificacion depende de la frecuencia de las palabras del vocabulario utilizado\n",
    "* Este preceso busca poder convertir cualquier dataset a modo reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación del vocabulario\n",
    "\n",
    "* Contaremos las palabras para generar el vocabulario que nos permitirán establecer la frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(url):\n",
    "  \"\"\"\n",
    "  Cargamos los datos del dataset publimed\n",
    "  Retornamos un dataframe con los datos\n",
    "  \"\"\"\n",
    "  return pd.read_csv(url, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def puntuacion(text):\n",
    "  \"\"\"\n",
    "  Recibe un texto y elimina los signos de puntuacion\n",
    "  \"\"\"\n",
    "  forbidden = (\"?\", \"¿\", \"¡\", \"!\", \",\", \".\", \";\", \":\", \"-\", \"[\", \"]\", \"'\", \"(\", \")\", \"{\", \"}\", '\"', \"/\")\n",
    "  texto = text.lower()\n",
    "  aux = \"\" \n",
    "  for v in texto:\n",
    "    if not v in forbidden:\n",
    "      aux += v\n",
    "  aux = aux.replace(\"  \", \" \")\n",
    "  return aux\n",
    "\n",
    "def solo_oraciones(data, atributo=\"title\"):\n",
    "  \"\"\"\n",
    "  Obtiene una lista de las oraciones\n",
    "  de los atributos seleccionados de data\n",
    "  \"\"\"\n",
    "  return list(puntuacion(x) for x in set(data[atributo]) if type(x) == str)\n",
    "\n",
    "def todas_oraciones(data, atributos=['title', 'abstract']):\n",
    "  \"\"\"\n",
    "  Retorna todas las oraciones de la data\n",
    "  que pertenecen a los atributos seleccioandos\n",
    "  \"\"\"\n",
    "  return reduce(lambda x,y: x + solo_oraciones(data, y), atributos, list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulario en base a la frecuencia\n",
    "\n",
    "* El vocabulario se basa principalmente en la frecuencia que posee cada palabra dentro del dataset\n",
    "* De esta forma, necesitamos recolectar la frecuencia con la cual aparecen\n",
    "* A partir de su frecuencia ordenamos las palabras de mayor a menor\n",
    "* Finalmentente la representación de la i-ésima palabra dentro de esta recolección, será precisamente el valor i. Con lo cual palabras muy utilizadas tendrán valores bajos y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(counts, string):\n",
    "  \"\"\"\n",
    "  Recibe un registro de los conteos de las palabras\n",
    "  y un string.\n",
    "  Actualiza el contador de las palabras y lo retorna\n",
    "  \"\"\"\n",
    "  words = string.split()\n",
    "  for word in words:\n",
    "    if word in counts:\n",
    "      counts[word] += 1\n",
    "    else:\n",
    "      counts[word] = 1\n",
    "  return counts\n",
    "\n",
    "\n",
    "def obtener_palabras(data, atributos=['title', 'abstract']):\n",
    "  \"\"\"\n",
    "  Recibe el data completo\n",
    "  Retorna un arreglo de todas las palabras\n",
    "  de los atributos que se deseen\n",
    "  \"\"\"\n",
    "  oraciones, palabras = todas_oraciones(data, atributos), dict()\n",
    "  oraciones = list(set(oraciones))\n",
    "  for frase in oraciones:\n",
    "    palabras = word_count(palabras, frase)\n",
    "  return palabras\n",
    "\n",
    "\n",
    "def construir_vocabulario(palabras):\n",
    "  \"\"\"\n",
    "  Cuenta la cantidad de veces que son utilizadas las palabras\n",
    "  retorna un arreglo de las palabras con su frecuencia\n",
    "  \"\"\"\n",
    "  keys = ['word', 'frequency']\n",
    "  vocabulario = list(dict(zip(keys, tupla)) for tupla in palabras.items())\n",
    "  return sorted(vocabulario, key = lambda i: i['frequency'], reverse=True)\n",
    "\n",
    "\n",
    "def asignar_id(vocabulario):\n",
    "  \"\"\"\n",
    "  Agrega un id para las palabras utilizadas\n",
    "  \"\"\"\n",
    "  for idx, palabra in enumerate(vocabulario):\n",
    "    palabra['id'] = idx + 3\n",
    "  return vocabulario\n",
    "\n",
    "\n",
    "def generar_vocabulario(data):\n",
    "  \"\"\"\n",
    "  A partir de la data determina las palabras y genera el vocabulario\n",
    "  para realizar la configuracion de los datos\n",
    "  \"\"\"\n",
    "  palabras = obtener_palabras(data)\n",
    "  vocabulario = construir_vocabulario(palabras)\n",
    "  return asignar_id(vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realización de la codificiacion\n",
    "\n",
    "* A partir del vocabulario generado que incluye la frecuencia de uso de las palabras\n",
    "* Generamos la configuracion de los datos utilizados\n",
    "* Esto nos permitirá obtener una representacion de cada documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_labels(data):\n",
    "  registro, topicos, keys = dict(), list(), ['topic', 'frequency']\n",
    "\n",
    "  for index, row in data.iterrows():\n",
    "    topico = row['topic_name']\n",
    "    if topico in registro:\n",
    "      registro[topico] += 1\n",
    "    else:\n",
    "      registro[topico] = 1\n",
    "\n",
    "  for tupla in registro.items():\n",
    "    tupla_actual = dict(zip(keys, tupla))\n",
    "    topicos.append(tupla_actual)\n",
    "\n",
    "  topicos = sorted(topicos, key = lambda i: i['frequency'], reverse=True)\n",
    "\n",
    "  retorno = dict()\n",
    "  for idx, topico in enumerate(topicos):\n",
    "    topico['id_label'] = idx+1\n",
    "    retorno[topico['topic']] = idx+1\n",
    "    #print(topico['topic'])\n",
    "  return topicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_topic(nombre, label_topic):\n",
    "  for idx, elemento in enumerate(label_topic):\n",
    "    if nombre == elemento['topic']:\n",
    "      return idx+1\n",
    "\n",
    "def id_topicos(data, label_topic):\n",
    "    return list( encontrar_topic(row['topic_name'], label_topic) for _, row in data.iterrows() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unir_contenido(row):\n",
    "  if row['code_abstract'] is None:\n",
    "    return row['code_title']\n",
    "  return row['code_title'] + row['code_abstract']\n",
    "\n",
    "def generar_contenido(data):\n",
    "  return list(unir_contenido(row) for _, row in data.iterrows())\n",
    "\n",
    "def generar_dataset(data):\n",
    "  retorno = dict()\n",
    "  label_topic = generar_labels(data)\n",
    "  retorno['content'] = generar_contenido(data)\n",
    "  retorno['label'] = id_topicos(data, label_topic)\n",
    "  return retorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de variables para dataset\n",
    "\n",
    "* Generamos opciones para poder manejar el dataset y su separacion\n",
    "* Es preferible realizar filtros en la cantidad y tipo de palabras que vamos a usar\n",
    "    * Puede ser que no nos interese usar palabras poco usadas en el dataset, para mejorar el tiempo que toma la factorización\n",
    "    * O bien, quitar las palabras más frecuentes que por lo general corresponden a artículos que no aportan en la discriminación de los tópicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_ranking(elemento, num_words, skip_top):\n",
    "  retorno = list()\n",
    "  maximo = num_words + skip_top\n",
    "  for x in elemento:\n",
    "    if skip_top < x < maximo:\n",
    "      retorno.append(x)\n",
    "  return retorno\n",
    "\n",
    "def filtros(content, max_len, num_words, skip_top):\n",
    "  retorno = list()\n",
    "  for elemento in content:\n",
    "    if num_words and elemento:\n",
    "      elemento = filtro_ranking(elemento, num_words, skip_top)\n",
    "    if max_len and elemento:\n",
    "      elemento = elemento[:max_len]\n",
    "    retorno.append(elemento)\n",
    "  return retorno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_id(vocabulario, palabra, atributo, idx):\n",
    "  \"\"\"\n",
    "  Encontramos el id que posee la palabra en el vocabulario\n",
    "  \"\"\"\n",
    "  for tupla in vocabulario:\n",
    "    if tupla['word'] == palabra:\n",
    "      return(tupla['id'])\n",
    "  return None\n",
    "\n",
    "def to_code(vocabulario, oracion, atributo, idx):\n",
    "  \"\"\"\n",
    "  Codificamos las frases utilizadas para el atributo\n",
    "  \"\"\"\n",
    "  oracion = oracion.strip().split()\n",
    "  return list(encontrar_id(vocabulario, palabra, atributo, idx) for palabra in oracion)\n",
    "\n",
    "def code_atributo(data, vocabulario, atributo):\n",
    "  \"\"\"\n",
    "  Codifica el atributo a partir de la representacion\n",
    "  a partir de la frecuencia suada en ese atributo\n",
    "  \"\"\"\n",
    "  columna_atributo = list()\n",
    "  for index, row in data.iterrows():\n",
    "    if type(row[atributo]) is str:\n",
    "      auxiliar = to_code(vocabulario, puntuacion(row[atributo]), atributo, index)\n",
    "    else:\n",
    "      row[atributo], auxiliar = None, None\n",
    "    columna_atributo.append(auxiliar)\n",
    "  data[f'code_{atributo}'] = columna_atributo\n",
    "  return data\n",
    "\n",
    "def code_atributos(data, vocabulario, atributos=['title', 'abstract']):\n",
    "  \"\"\"\n",
    "  Codifica los atributos de la data para\n",
    "  una representacion de frecuencia de palabras\n",
    "  \"\"\"\n",
    "  for atributo in atributos:\n",
    "    data = code_atributo(data, vocabulario, atributo)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data, vocabulario, test_split, max_len=None, num_words=None, skip_top=None):\n",
    "  #data = cargar_datos(url)\n",
    "  #vocabulario = generar_vocabulario(data)\n",
    "  data_procesada = code_atributos(data, vocabulario)\n",
    "  dataset = generar_dataset(data_procesada)\n",
    "  largo = len(dataset['content'])\n",
    "  len_train = int(largo*test_split)\n",
    "  #len_test = largo - len_train\n",
    "  \n",
    "  #print(largo, len_train, test_split)\n",
    "  \n",
    "  dataset['content'] = filtros(dataset['content'], max_len, num_words, skip_top)\n",
    "  \n",
    "  train = np.array(dataset['content'][len_train:]), np.array(dataset['label'][len_train:])\n",
    "  test = np.array(dataset['content'][:len_train]), np.array(dataset['label'][:len_train])\n",
    "  #print(len(train), len(test))\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edición del dataset\n",
    "\n",
    "* Generamos funciones para poder representar mejor el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_repetidos(x_train, y_train):\n",
    "  x_retorno, y_retorno = list(), list()\n",
    "  \n",
    "  for i, elemento in enumerate(x_train):\n",
    "    if x_retorno and elemento == x_retorno[-1]:\n",
    "      y_retorno[-1].append(y_train[i])\n",
    "      continue\n",
    "    x_retorno.append(elemento)\n",
    "    y_retorno.append([y_train[i], ])\n",
    "  return x_retorno, y_retorno\n",
    "\n",
    "def mensaje_code(vocabulario, code):\n",
    "  retorno = list( to_word(x, vocabulario) for x in code)\n",
    "  return \" \".join(retorno)\n",
    "\n",
    "def to_word(idx, vocabulario):\n",
    "  return vocabulario[idx-3]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_vacios(x_train, y_train):\n",
    "  \"\"\"\n",
    "  Por diferentes opciones pueden quedar valores vacios\n",
    "  Eliminamos esos valores vacios\n",
    "  \"\"\"\n",
    "  x_retorno, y_retorno = list(), list()\n",
    "  for i, x in enumerate(x_train):\n",
    "    if x:\n",
    "      x_retorno.append(x)\n",
    "      y_retorno.append(y_train[i])\n",
    "  return x_retorno, y_retorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carguemos los datos\n",
    "\n",
    "* Vamos a cargar los datos según caracteristicas que hagan más fácil de entender el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETROS\n",
    "\n",
    "num_words = 100 # solo tomaremos las 100 primeras palabras\n",
    "skip_top = 15 # palabras que no consideraremos\n",
    "max_len = None # N° de palabras vocabulario\n",
    "test_split = 0.05 # Porcentaje de palabras en el test set\n",
    "url = '../dataset/publimed_medium.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_labels(labels):\n",
    "  return list(x['topic'] for x in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cargar_datos(url)\n",
    "vocabulario = generar_vocabulario(data)\n",
    "label_topic = mapping_labels(generar_labels(data))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data(data,\n",
    "                                                 vocabulario,\n",
    "                                                 test_split=test_split,\n",
    "                                                 max_len=max_len,\n",
    "                                                 num_words=num_words,\n",
    "                                                 skip_top=skip_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train set: (3325,), (3325,)\n",
      "Tamaño test set: (175,), (175,)\n",
      "Cantidad clases: 9\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño train set: {x_train.shape}, {y_train.shape}')\n",
    "print(f'Tamaño test set: {x_test.shape}, {y_test.shape}')\n",
    "print(f'Cantidad clases: {max(max(y_train), max(y_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = eliminar_vacios(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clases = max(y_train)\n",
    "n_clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1 - freq: 1152\n",
      "id: 2 - freq: 1146\n",
      "id: 3 - freq: 1144\n",
      "id: 4 - freq: 53\n",
      "id: 5 - freq: 1\n",
      "id: 6 - freq: 1\n",
      "id: 7 - freq: 1\n",
      "id: 8 - freq: 1\n",
      "id: 9 - freq: 1\n"
     ]
    }
   ],
   "source": [
    "for label in generar_labels(data):\n",
    "  print(f\"id: {label['id_label']} - freq: {label['frequency']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicamos Rank-2\n",
    "\n",
    "Ya que tenemos el dataset listo para poder trabajar en estilo \"Reuters\"\n",
    "\n",
    "* Vamos a importar las funciones del tutorial del uso de reuters\n",
    "* Utilizamos las funciones para poder separar en ciertos grupos\n",
    "\n",
    "### Importamos las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ipynb.fs.full.reuters_functions as reu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conteo_labels(n, p):\n",
    "  \"\"\"\n",
    "  Para una mejor representacion de los labels\n",
    "  utilizaremos medidores para que no supere ciertas barreras\n",
    "  \"\"\"\n",
    "  return list( [0, randrange(p-5, p+5)] for _ in range(n) )\n",
    "\n",
    "\n",
    "def reducir_labels(data_array, labels, k=7, pivote=25):\n",
    "  \"\"\"\n",
    "  Filtramos los documentos que pertenezcan a las primeras k clases\n",
    "  Retornamos el arreglo con los documentos y sus correspondientes labels\n",
    "  \"\"\"\n",
    "  \n",
    "  conteo = conteo_labels(max(labels), pivote)\n",
    "  retorno, retorno_labels = list(), list()\n",
    "  for i in range(len(data_array)):\n",
    "    if labels[i] < k and conteo[labels[i]][0] < conteo[labels[i]][1]:\n",
    "      retorno.append(data_array[i])\n",
    "      retorno_labels.append(labels[i])\n",
    "      conteo[labels[i]][0] += 1\n",
    "  return np.array(retorno), retorno_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = reducir_labels(x_train, y_train, k=n_clases, pivote=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasar los datos a matriz doc-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos tokenizer para producirlo\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tkn = Tokenizer(num_words=num_words) # tamaño del vocabulario\n",
    "num_clases = max(y_data) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruimos la matriz pasando los datos a binario\n",
    "\n",
    "x_data_bin = tkn.sequences_to_matrix(x_data, mode='binary')\n",
    "y_data_cat = to_categorical(y_data, num_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set \n",
      "\n",
      "  Values: (98, 100)    n° docs x n° words \n",
      "  Ej: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "\n",
      "\n",
      "  Labels: (98, 9)   (usaremos este) \n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los como queda la representacion\n",
    "\n",
    "entry = 10\n",
    "print(f'Train Set \\n\\n  Values: {x_data_bin.shape}    n° docs x n° words \\n  Ej: {x_data_bin[entry]}\\n')\n",
    "print(f'\\n  Labels: {y_data_cat.shape}   (usaremos este) \\n {y_data_cat[entry]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siguiendo la interpretación del paper\n",
    "\n",
    "A_matrix = np.transpose(x_data_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_palabras_destacadas(lista_arbol, index_to_word, cantidad=10):\n",
    "  for nodo in lista_arbol:\n",
    "    if nodo['matrix'].shape[1] == 1:\n",
    "      nodo['W'] = nodo['matrix']\n",
    "    elif 'W' not in nodo.keys():\n",
    "      nodo['W'], nodo['H'] = reu.calcular_descomposicion(nodo['matrix'])\n",
    "    nodo['destacadas'] = reu.palabras_destacadas(nodo['W'], index_to_word, cantidad)\n",
    "  return lista_arbol\n",
    "\n",
    "\n",
    "def topicos_relevantes(y_data, columnas, mapping):\n",
    "  \"\"\"\n",
    "  Ordena los topicos relevantes para cada nodo\n",
    "  del arbol jerarquico\n",
    "  \"\"\"\n",
    "  counts = dict()\n",
    "  for col in columnas:\n",
    "    if str(y_data[col]) in counts:\n",
    "      counts[str(y_data[col])] += 1\n",
    "    else:\n",
    "      counts[str(y_data[col])] = 1\n",
    "      \n",
    "  keys = ['label', 'frequency']\n",
    "\n",
    "  auxiliar = list(dict(zip(keys, tupla)) for tupla in counts.items())\n",
    "\n",
    "  labels = sorted(auxiliar, key = lambda i: i['frequency'], reverse=True)\n",
    "  \n",
    "  for elemento in labels:\n",
    "    elemento['label'] = int(elemento['label'])\n",
    "    elemento['label_name'] = mapping[elemento['label']-1]\n",
    "  return labels\n",
    "\n",
    "def palabras_relevantes(palabras):\n",
    "  \"\"\"\n",
    "  Selecciona las palabras más relevantes para cada nodo\n",
    "  del arbol jerarquico\n",
    "  \"\"\"\n",
    "  return list(x['word']['word'] for x in palabras[:5])\n",
    "\n",
    "\n",
    "def presentar_nodos(lista_arbol, y_data, mapping):\n",
    "  \"\"\"\n",
    "  Imprime una vision preeliminar de los nodos del arbol jerarquico\n",
    "  \"\"\"\n",
    "  for nodo in lista_arbol:\n",
    "    print(f\"Nodo {nodo['id']}\")\n",
    "    print(f\"  parent: {nodo['parent']} - leafs {nodo['hijos']}\\n\")\n",
    "    topicos = topicos_relevantes(y_data, nodo['columnas'], mapping)\n",
    "    for topico in topicos:\n",
    "      print(f\"label: {topico['label']}, frecuencia: {topico['frequency']}\")\n",
    "      print(f\"  {topico['label_name']}\")\n",
    "    print(\"\")\n",
    "    palabras = palabras_relevantes(nodo['destacadas'])\n",
    "    frase = \"\"\n",
    "    for w in palabras:\n",
    "      if frase:\n",
    "        frase += \" / \"\n",
    "      frase += w\n",
    "    print(frase, \"\\n----------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación NMF Rank-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "\n",
    "numero_nodos = 4 # cantidad nodos para crear\n",
    "beta = 1.1 # diferencia de tamaño mínima que habrá entre los nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = Tokenizer(num_words=num_words) # tamaño del vocabulario\n",
    "num_clases = max(y_data) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = reu.jerarquizacion(A_matrix, vocabulario, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_arbol = obtener_palabras_destacadas(lista_arbol, vocabulario, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_arbol = reu.limpiar_lista(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#presentar_nodos(lista_arbol, y_data, label_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def top_words(palabras):\n",
    "  arreglo_palabras = dict((x['word']['word'], x['word']['frequency']) for x in palabras)\n",
    "  return dict(sorted(arreglo_palabras.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "def arreglar_destacadas(lista_nodos):\n",
    "  for nodo in lista_nodos:\n",
    "    nodo['destacadas'] = top_words(nodo['destacadas'])\n",
    "  return lista_nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_caracteristicas(lista_nodos, caracteristicas):\n",
    "  retorno = list()\n",
    "  for elemento in lista_nodos:\n",
    "    actual = dict()\n",
    "    for x in caracteristicas:\n",
    "      actual[x] = elemento[x]\n",
    "    retorno.append(actual)\n",
    "  return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = arreglar_destacadas(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = seleccionar_caracteristicas(lista_arbol, ['id', 'parent', 'hijos', 'destacadas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_palabras(lista_arbol, url=None):\n",
    "  \"\"\"\n",
    "  Funcion que nos permite guardar las palabras\n",
    "  contenidas en el json de la url\n",
    "  \"\"\"\n",
    "  if url is None:\n",
    "    url = './publimed_graph.json'\n",
    "  with open(url, \"w\") as write_file:\n",
    "    write_file.write(json.dumps(lista_arbol))\n",
    "\n",
    "def obtener_palabras(url=None):\n",
    "  \"\"\"\n",
    "  Funcion que nos permite cargas las palabras\n",
    "  contenidas en el json de la url\n",
    "  \"\"\"\n",
    "  if url is None:\n",
    "    url = './publimed_graph.json'\n",
    "  with open(url, \"r\") as read_file:\n",
    "    lista_reuters = json.load(read_file)\n",
    "  return lista_reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_palabras(lista_arbol)\n",
    "lista_publimed = obtener_palabras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación del árbol jerárquico\n",
    "\n",
    "Utilizaremos la librería graphviz para representar la factorización realizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_palabras(grafo, elemento):\n",
    "  \"\"\"\n",
    "  Recibe el grafo al elemento que se quiere agregar\n",
    "  Itera sobre las palabras destacadas del  elemento\n",
    "  añadiendolas según una estructura\n",
    "  \"\"\"\n",
    "  x = list(elemento['destacadas'].keys())\n",
    "  largo = len(x)\n",
    "  retorno = ''\n",
    "  for i in range(0, largo, 2):\n",
    "    a, b = i, i+1\n",
    "    actual = f'<w{a}> {x[a]} | <w{b}> {x[b]}'\n",
    "    retorno += '{ ' + actual + ' }'\n",
    "    if b < largo-1:\n",
    "      retorno += ' | '\n",
    "  grafo.node(f\"node{elemento['id']}\", nohtml(retorno))\n",
    "\n",
    "def generar_grafico(lista_nodos):\n",
    "  \"\"\"\n",
    "  Recibe la lista de nodos con la información de\n",
    "  las palabras destacadas de cada nodo\n",
    "  Itera sobre cada nodo, añadiendo la información de\n",
    "  cada elemento\n",
    "  Finalmente realiza la visualización del grafo\n",
    "  \"\"\"\n",
    "  dot = Digraph(node_attr={'color': 'lightblue2',\n",
    "                         'style': 'filled',\n",
    "                         'shape': 'record',\n",
    "                         'height': '.1',\n",
    "                         'label':\"Curve edges\"})\n",
    "                         #splines=ortho,\n",
    "                         #nodesep=0.8\n",
    "      \n",
    "  for nodo in lista_nodos:\n",
    "    agregar_palabras(dot, nodo)\n",
    "    largo = len(nodo['destacadas'])\n",
    "    if nodo['parent']:\n",
    "\n",
    "      if (largo/2) % 2 == 1:\n",
    "        p = int( (len(nodo['destacadas'])/2 + 1)/2)\n",
    "        dot.edge(f\"node{nodo['parent']}:w{p+1}\", f\"node{nodo['id']}:w{p}\")\n",
    "      else:\n",
    "        dot.edge(f\"node{nodo['parent']}\", f\"node{nodo['id']}\")\n",
    "\n",
    "  display(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"975pt\" height=\"304pt\"\n",
       " viewBox=\"0.00 0.00 974.50 304.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-300 970.5,-300 970.5,4 -4,4\"/>\n",
       "<!-- node1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>node1</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"456,-249.5 456,-295.5 633,-295.5 633,-249.5 456,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">or</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"456,-272.5 521,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"488.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">common</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"521,-249.5 521,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">diagnosis</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"521,-272.5 592,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gallstones</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"592,-249.5 592,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">liver</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"592,-272.5 633,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cbd</text>\n",
       "</g>\n",
       "<!-- node2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>node2</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"334,-166.5 334,-212.5 611,-212.5 611,-166.5 334,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"372.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">biliary</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"334,-189.5 411,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"372.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gallbladder</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"411,-166.5 411,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"431\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">by</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"411,-189.5 451,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"431\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ercp</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"451,-166.5 451,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"531\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retrograde</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"451,-189.5 611,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"531\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cholangiopancreatography</text>\n",
       "</g>\n",
       "<!-- node1&#45;&gt;node2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>node1:w3&#45;&gt;node2:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M556.5,-249.5C556.5,-195.0112 446.6787,-260.8845 432.0931,-222.3813\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"435.5472,-221.8154 430.5,-212.5 428.6364,-222.9296 435.5472,-221.8154\"/>\n",
       "</g>\n",
       "<!-- node3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>node3</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"629.5,-166.5 629.5,-212.5 753.5,-212.5 753.5,-166.5 629.5,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"644.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">by</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"629.5,-189.5 659.5,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"644.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">be</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"659.5,-166.5 659.5,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"682.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cases</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"659.5,-189.5 705.5,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"682.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">study</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"705.5,-166.5 705.5,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"729.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">has</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"705.5,-189.5 753.5,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"729.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cystic</text>\n",
       "</g>\n",
       "<!-- node1&#45;&gt;node3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>node1:w3&#45;&gt;node3:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M556.5,-249.5C556.5,-195.0112 666.3213,-260.8845 680.9069,-222.3813\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"684.3636,-222.9296 682.5,-212.5 677.4528,-221.8154 684.3636,-222.9296\"/>\n",
       "</g>\n",
       "<!-- node4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>node4</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"135,-83.5 135,-129.5 322,-129.5 322,-83.5 135,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"167.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ercp</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"135,-106.5 200,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"167.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gallstone</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"200,-83.5 200,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"236\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retrograde</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"200,-106.5 272,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"236\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">surgery</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"272,-83.5 272,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">which</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"272,-106.5 322,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">group</text>\n",
       "</g>\n",
       "<!-- node2&#45;&gt;node4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>node2:w3&#45;&gt;node4:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M430.5,-166.5C430.5,-82.4953 252.8137,-205.7874 237.5438,-139.5972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"241.0098,-139.0871 236.5,-129.5 234.0469,-139.8069 241.0098,-139.0871\"/>\n",
       "</g>\n",
       "<!-- node5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>node5</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"340,-83.5 340,-129.5 527,-129.5 527,-83.5 340,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gallbladder</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"340,-106.5 417,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"378.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">or</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"417,-83.5 417,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"435\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">this</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"417,-106.5 453,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"435\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">an</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"453,-83.5 453,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"490\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gallstone</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"453,-106.5 527,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"490\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ultrasound</text>\n",
       "</g>\n",
       "<!-- node2&#45;&gt;node5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>node2:w3&#45;&gt;node5:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M430.5,-166.5C430.5,-153.9249 433.3714,-148.6901 434.7622,-139.6705\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"438.2672,-139.727 435.5,-129.5 431.2856,-139.2205 438.2672,-139.727\"/>\n",
       "</g>\n",
       "<!-- node6 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>node6</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"552.5,-83.5 552.5,-129.5 764.5,-129.5 764.5,-83.5 552.5,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"606.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">biliary</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"552.5,-106.5 660.5,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"606.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cholecystectomy</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"660.5,-83.5 660.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"678.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">this</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"660.5,-106.5 696.5,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"678.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">as</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"696.5,-83.5 696.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"730.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">diagnosis</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"696.5,-106.5 764.5,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"730.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">patient</text>\n",
       "</g>\n",
       "<!-- node3&#45;&gt;node6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>node3:w3&#45;&gt;node6:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M682.5,-166.5C682.5,-153.9656 680.2029,-148.679 679.0902,-139.6553\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"682.5744,-139.28 678.5,-129.5 675.5862,-139.6863 682.5744,-139.28\"/>\n",
       "</g>\n",
       "<!-- node7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>node7</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"782.5,-83.5 782.5,-129.5 966.5,-129.5 966.5,-83.5 782.5,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"808.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">biliary</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"782.5,-106.5 834.5,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"808.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stones</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"834.5,-83.5 834.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"874\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cases</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"834.5,-106.5 913.5,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"874\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pancreatitis</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"913.5,-83.5 913.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"940\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">patient</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"913.5,-106.5 966.5,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"940\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">two</text>\n",
       "</g>\n",
       "<!-- node3&#45;&gt;node7 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>node3:w3&#45;&gt;node7:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M682.5,-166.5C682.5,-83.7484 857.4386,-204.6958 872.4724,-139.4496\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"875.954,-139.8067 873.5,-129.5 868.9911,-139.0875 875.954,-139.8067\"/>\n",
       "</g>\n",
       "<!-- node8 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>node8</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"0,-.5 0,-46.5 257,-46.5 257,-.5 0,-.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">or</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"0,-23.5 77,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"38.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">endoscopic</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"77,-.5 77,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"131\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cholecystectomy</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"77,-23.5 185,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"131\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">laparoscopic</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"185,-.5 185,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"221\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gallstone</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"185,-23.5 257,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"221\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lithotripsy</text>\n",
       "</g>\n",
       "<!-- node4&#45;&gt;node8 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>node4:w3&#45;&gt;node8:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M236.5,-83.5C236.5,-38.0796 148.02,-86.5641 133.5038,-56.5499\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.8878,-55.6226 131.5,-46.5 130.023,-56.9914 136.8878,-55.6226\"/>\n",
       "</g>\n",
       "<!-- node9 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>node9</title>\n",
       "<polygon fill=\"#b2dfee\" stroke=\"#b2dfee\" points=\"275,-.5 275,-46.5 428,-46.5 428,-.5 275,-.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"301\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">biliary</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"275,-23.5 327,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"301\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">were</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"327,-.5 327,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"342\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">or</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"327,-23.5 357,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"342\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">by</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"357,-.5 357,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"392.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">as</text>\n",
       "<polyline fill=\"none\" stroke=\"#b2dfee\" points=\"357,-23.5 428,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"392.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gallstones</text>\n",
       "</g>\n",
       "<!-- node4&#45;&gt;node9 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>node4:w3&#45;&gt;node9:w2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M236.5,-83.5C236.5,-38.0796 324.98,-86.5641 339.4962,-56.5499\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"342.977,-56.9914 341.5,-46.5 336.1122,-55.6226 342.977,-56.9914\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f1925014198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generar_grafico(lista_publimed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
