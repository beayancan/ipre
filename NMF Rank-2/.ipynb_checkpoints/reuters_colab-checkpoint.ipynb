{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FOnO1SD-pzs"
   },
   "source": [
    "# NMF Rank-2 con dataset Reuters\n",
    "\n",
    "Autor: Benjamin Ayancán, PUC Chile\n",
    "Tutor: Denis Parra, PUC Chile\n",
    "\n",
    "En el siguiente notebook desarrollaremos un ejemplo de cómo poder generar una descomposición jerarquica a través del algoritmo de rango bajo NMF rank-2.\n",
    "\n",
    "* Para este tutorial usaremos el dataset de noticias Reuters que nos entrega la libería `keras`\n",
    "\n",
    "* Los aspectos teoricos y detalles del algoritmo son abordados en el  siguiente [notebook de Observablehq](https://observablehq.com/@beayancan/descomposicion-jerarquica)\n",
    "\n",
    "* Para hacer más pedagógico el ejemplo se va a reducir tanto la cantidad de datos (filas) como la cantidad de features (columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLET-ev4s9Rp"
   },
   "source": [
    "---\n",
    "\n",
    "## Configuración\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "--> Si lo estás ejecutando en un `jupyter notebook` debes instalar las siguientes librerías\n",
    "\n",
    "```py\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "```\n",
    "\n",
    "--> Si lo estás ejecutando en `colab`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEb5CzWsY-xO"
   },
   "outputs": [],
   "source": [
    "# Chequeamos que nuestro soporte no tenga problemas\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hb3X252TY0H2",
    "outputId": "1bb6d096-4898-4c6d-995a-462ac45e6fc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importamos las liberías que vamos a utilizar\n",
    "# herramientas y el dataset\n",
    "\n",
    "import os, sys\n",
    "import keras\n",
    "import statistics\n",
    "import collections\n",
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPD06Xvdtbp7"
   },
   "source": [
    "---\n",
    "\n",
    "## Reuters\n",
    "\n",
    "#### ¿Por qué usar esta librería?\n",
    "\n",
    "Reuters es un repositorio de documentos que podemos utilizar a través de `keras` o bien descargarlo en su [página web](http://konect.cc/networks/gottron-reuters/). Esta posee las siguientes características\n",
    "\n",
    "* Son un conjunto de 11.228 noticias, etiquetados en 46 tópicos.\n",
    "\n",
    "\n",
    "* Está preprocesado según un ranking de palabras de un volabulario, es decir su representación es a través de las posiciones en el ranking de las palabras de un documento\n",
    "* Posee funciones sencillas que nos ayudan a manejar cómo representar los documentos sin gastar mucho tiempo en su preprocesamiento\n",
    "* Se enfoca en el contenido de un documento, las palabras que lo representan, en vez del mensaje que este entregue\n",
    "\n",
    "---\n",
    "\n",
    "#### Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBBfF4DIuHC-"
   },
   "outputs": [],
   "source": [
    "# PARAMETROS\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters/load_data\n",
    "\n",
    "# Cantidad de palabras significativas del vocabulario a usar\n",
    "\n",
    "# num_words = None # incluirlas todas\n",
    "num_words = 100 # solo tomaremos las 100 primeras palabras\n",
    "skip_top = 0 # palabras que no consideraremos\n",
    "\n",
    "# máximo N° de palabras para representar a un documento\n",
    "max_len = None # todas\n",
    "# max_len = 50\n",
    "\n",
    "# Porcentaje de palabras para usar en el test set\n",
    "test_split = 0.4 # train set: 97.5%, test set: 2.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MPNg4lWueWs9",
    "outputId": "cb6c810e-43e2-49e0-9614-3cee8e1a852c"
   },
   "outputs": [],
   "source": [
    "# Cargamos los de datos de clasificación de noticias de Reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words,\n",
    "                                                         maxlen=max_len,\n",
    "                                                         test_split=test_split,\n",
    "                                                         skip_top=skip_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "xrzJdAjwWnvA",
    "outputId": "cf86be6d-256b-4a1c-95f6-8143ea984288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train set: (6736,)\n",
      "Tamaño test set: (4492,)\n",
      "Cantidad clases: 46\n"
     ]
    }
   ],
   "source": [
    "# Revisamos cómo fueron cargados los datos\n",
    "\n",
    "# y_train, y_test contendrán los labels de las clases\n",
    "\n",
    "num_clases = max(y_train) + 1\n",
    "\n",
    "print(f'Tamaño train set: {x_train.shape}')\n",
    "print(f'Tamaño test set: {x_test.shape}')\n",
    "print(f'Cantidad clases: {num_clases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tW0E5KIwiCi"
   },
   "source": [
    "### Qué es lo que contienen\n",
    "* Cada elemento del set contiene los índices de las palabras más utilizadas por un documento\n",
    "\n",
    "* Las palabras están ordenadas según su frecuencia de aparición\n",
    "* Además cada documento pertenece a un tópico en especifico\n",
    "* Notar por el `x_train.shape` que las representaciones no tienen un largo especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "2SqXKHd1gxs8",
    "outputId": "c23a4019-c6e0-43ef-e894-2c6e51c8eaf7"
   },
   "outputs": [],
   "source": [
    "# Mostremos algunos ejemplos\n",
    "# for i in range(1,15, 3):\n",
    "#   print(f'Doc: {i},  largo: {len(x_test[i])}, clase {y_test[i]}')\n",
    "#   print(f'   contenido: {x_test[i]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "colab_type": "code",
    "id": "TmYUZB3gtZBd",
    "outputId": "f60e3dcb-7302-4b79-fc36-f6a169c9616c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Las clases y sus estadísticas\n",
      "Idx  Clase                train  test  Palabras\n",
      "    0 cocoa                   41    26   227.10\n",
      "    1 grain                  331   206   184.57\n",
      "    2 veg-oil                 53    41   189.55\n",
      "    3 earn                  2379  1593    89.53\n",
      "    4 acq                   1441   982   137.61\n",
      "    5 wheat                   11    11   215.82\n",
      "    6 copper                  33    29   153.64\n",
      "    7 housing                 14     5   196.00\n",
      "    8 money-supply           108    69   190.17\n",
      "    9 coffee                  81    45   220.44\n",
      "   10 sugar                   94    60   199.59\n",
      "   11 trade                  295   178   257.92\n",
      "   12 reserves                37    25   170.32\n",
      "   13 ship                   129    80   166.84\n",
      "   14 cotton                  17    11   154.47\n",
      "   15 carcass                 16    13   182.12\n",
      "   16 crude                  317   226   217.26\n",
      "   17 nat-gas                 29    22   148.07\n",
      "   18 cpi                     54    32   150.19\n",
      "   19 money-fx               414   268   188.41\n",
      "   20 interest               202   137   198.63\n",
      "   21 gnp                     78    49   272.90\n",
      "   22 meal-feed               10    12   178.30\n",
      "   23 alum                    34    19   165.32\n",
      "   24 oilseed                 48    33   159.65\n",
      "   25 gold                    63    60   153.41\n",
      "   26 tin                     15    17   224.33\n",
      "   27 strategic-metal         12     7   136.00\n",
      "   28 livestock               41    17   178.63\n",
      "   29 retail                  16     7   287.62\n",
      "   30 ipi                     31    26   174.52\n",
      "   31 iron-steel              30    22   147.60\n",
      "   32 rubber                  28    14   205.68\n",
      "   33 heat                     9     7   129.00\n",
      "   34 jobs                    36    21   144.53\n",
      "   35 lei                     10     6   142.30\n",
      "   36 bop                     39    21   224.21\n",
      "   37 zinc                    13     8   181.69\n",
      "   38 orange                  13     9   121.54\n",
      "   39 pet-chem                19    10   165.79\n",
      "   40 dlr                     27    19   286.59\n",
      "   41 gas                     23    15   192.39\n",
      "   42 silver                   8     8   151.25\n",
      "   43 wpi                     15    12   132.67\n",
      "   44 hog                     10     7    84.70\n",
      "   45 lead                    12     7   143.17\n"
     ]
    }
   ],
   "source": [
    "mapping = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "           'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "           'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "           'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "           'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']\n",
    "\n",
    "train_count = collections.Counter(y_train)\n",
    "test_count = collections.Counter(y_test)\n",
    "total_words = [statistics.mean([len(e) for e in x_train[y_train.flatten() == i]]) for i in range(46)]\n",
    "\n",
    "print(\"         Las clases y sus estadísticas\")\n",
    "print(\"{:4s} {:20s} {:5s}  {:5s} {:7s}\".format(\"Idx\",\"Clase\", \"train\", \"test\", \"Palabras\"))\n",
    "for i in range(46):\n",
    "   print(\"{:5d} {:20s} {:5d} {:5d}   {:6.2f}\".format(i,mapping[i], train_count[i], test_count[i], total_words[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1QfRta5-2UO"
   },
   "source": [
    "### Qué es lo que representan\n",
    "* Solo tenemos los índices, pero ¿de qué?\n",
    "  * Son la posición rankeada de la palabra\n",
    "* Usamos la indexación del vocabulario del dataset para identificar la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Ses2uu-X6EiC",
    "outputId": "6579106d-530b-4ea8-ff0e-ef9581941f4f"
   },
   "outputs": [],
   "source": [
    "# Tenemos el vocabulario con las palabras y sus indices\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# Generamos un diccionario con el contenido\n",
    "index_to_word = { value+3 : key for key, value in word_index.items() }\n",
    "\n",
    "# Indices reservados\n",
    "index_to_word[0] = '-PAD-'   # 0: carpeta\n",
    "index_to_word[1] = '-START-' # 1: inicio secuencia\n",
    "index_to_word[2] = '-UNK-'   # 2: elemento no encontrado\n",
    "\n",
    "len_index = len(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtkSV7UNPdc9"
   },
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "* Para poder realizar los calculos, necesitamos\n",
    "  * Una estructura regular de datos\n",
    "  * Que cada documento posea un mismo largo\n",
    "\n",
    "* Pasaremos primero los datos a una menor dimensión reduciendo las palabras y eliminando lo innecesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjKzIVgY2M2U"
   },
   "outputs": [],
   "source": [
    "# Primero eliminaremos las referencias a elementos que no se encuentran\n",
    "# dentro de las 1000 palabras más usadas en el vocabulario\n",
    "# ademas de las entradas reservadas\n",
    "\n",
    "  # Eliminamos\n",
    "  # 0: '-PAD-'\n",
    "  # 1: '-START-'\n",
    "  # 2: '-UNK-'\n",
    "  # 12: '3'\n",
    "  # 17: 'reuter'\n",
    "\n",
    "def filtrar_relevante(arreglo, por_eliminar=[0,1,2]):\n",
    "  \"\"\"\n",
    "  Borra las palabras que pertenecen a los indices del array por_eliminar\n",
    "  \"\"\"\n",
    "  return list(filter(lambda x: x not in por_eliminar, arreglo))\n",
    "\n",
    "def eliminar_reservadas(x_array):\n",
    "  \"\"\"\n",
    "  Eliminamos las entradas reservadas y entradas inutiles\n",
    "  retorna el contenido homogeneo del doc\n",
    "  \"\"\"\n",
    "  por_eliminar = [0,1,2,12,17]\n",
    "  largo_test, = x_array.shape\n",
    "  for i in range(largo_test):\n",
    "    x_array[i] = filtrar_relevante(x_array[i], por_eliminar)\n",
    "  return x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVifRE33sxqN"
   },
   "outputs": [],
   "source": [
    "# Para hacer un ejemplo más sencillo de entender\n",
    "# Selecionaremos solo las primeras 7 clases\n",
    "\n",
    "def conteo_labels(n, p):\n",
    "  return list( [0, randrange(p-3, p+3)] for _ in range(n) )\n",
    "\n",
    "def reducir_labels(data_array, labels, k=7, pivote=25):\n",
    "  \"\"\"\n",
    "  Filtramos los documentos que pertenezcan a las primeras k clases\n",
    "  Retornamos el arreglo con los documentos y sus correspondientes labels\n",
    "  \"\"\"\n",
    "  \n",
    "  conteo = conteo_labels(max(labels), pivote)\n",
    "  retorno, retorno_labels = list(), list()\n",
    "  for i in range(len(data_array)):\n",
    "    if labels[i] < k and conteo[labels[i]][0] < conteo[labels[i]][1]:\n",
    "      retorno.append(data_array[i])\n",
    "      retorno_labels.append(labels[i])\n",
    "      conteo[labels[i]][0] += 1\n",
    "  return np.array(retorno), retorno_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5NPalNU7tAXU",
    "outputId": "68f3ec51-ac70-4414-d91a-ae128e5848f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165,)\n"
     ]
    }
   ],
   "source": [
    "x_test = eliminar_reservadas(x_test)\n",
    "x_data, y_data = reducir_labels(x_test, y_test, k=7, pivote=25)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "MbLfYLj3vI2m",
    "outputId": "f4b03fcf-6dea-4458-e898-871d68b0ea4d"
   },
   "outputs": [],
   "source": [
    "# Mostremos lo que contiene\n",
    "for i in range(1,15, 3):\n",
    "  #print(f'Doc: {i},  Largo: {len(x_data[i])}, Clase {y_data[i]}')\n",
    "  #print(f' {x_data[i]}', '\\n', ' '.join([index_to_word[word] for word in x_data[i]]), \"\\n\")\n",
    "  continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VV9CKo3L8Get"
   },
   "source": [
    "### Pasar los datos a matriz doc-term\n",
    "\n",
    "* Pasamos a una matriz $A \\in \\mathbb{R}^{m \\times n}$ donde $m$ es la cantidad de documentos y $n$ es la cantidad de palabras del vocabulario\n",
    "* Pasaremos los datos a una representación de $\\{0, 1\\}$\n",
    "* Representando la entrada $A[i,j]$ la aparición en el $i$-ésimo documento la $j$-ésima palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ngXLKqz6etw"
   },
   "outputs": [],
   "source": [
    "# Importamos tokenizer para producirlo\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tkn = Tokenizer(num_words=num_words) # tamaño del vocabulario\n",
    "num_clases = max(y_data) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2pvAU85QIr6"
   },
   "outputs": [],
   "source": [
    "# Contruimos la matriz pasando los datos a binario\n",
    "\n",
    "x_data_bin = tkn.sequences_to_matrix(x_data, mode='binary')\n",
    "y_data_cat = to_categorical(y_data, num_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "mVCpasedQepb",
    "outputId": "568305d5-dfb3-4f3b-aa4c-6ff3dac0b70c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: (165, 100) \n",
      " [0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "\n",
      "Test Set: (165, 7)   (usaremos este) \n",
      " [0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los como queda la representacion\n",
    "\n",
    "entry = 10\n",
    "print(f'Train Set: {x_data_bin.shape} \\n {x_data_bin[entry]}\\n')\n",
    "print(f'Test Set: {y_data_cat.shape}   (usaremos este) \\n {y_data_cat[entry]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox3JNVrwQc2o"
   },
   "outputs": [],
   "source": [
    "# Siguiendo la interpretación del paper\n",
    "\n",
    "A_matrix = np.transpose(x_data_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTEMF7ZhSrYl"
   },
   "source": [
    "# NMF Jerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aa4N91wyStwu"
   },
   "source": [
    "* Ya tenemos unos datos preprocesados de forma ideal para nuestro trabajo\n",
    "* Realizaremos la secuencia de NMF jerárquico siguiendo el paper\n",
    "  * [Fast Rank-2 Nonnegative Matrix Factorization for Hierarchical Document Clustering](https://smallk.github.io/papers/hierNMF2.pdf)\n",
    "\n",
    "* Recordar que el objetivo es minimizar la siguiente operación\n",
    "  $$\\min_{W \\geq 0, H \\geq 0} ||A - WH||_2^{2}$$\n",
    "  * A través de la resolución de los subproblemas convexos\n",
    "    $$\\min_{H \\geq 0} ||A - WH||_2^{2}$$\n",
    "    $$\\min_{W \\geq 0} ||A^T - H^T W^T||_2^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NcwIIZe32N7"
   },
   "source": [
    "## NMF Rank-2\n",
    "\n",
    "* Usaremos el algoritmo Rank-2 para generar una estructura de árbol binario jerárquico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9slMc7UPuZPW"
   },
   "outputs": [],
   "source": [
    "def rank2(A, W):\n",
    "  \"\"\"\n",
    "  Recibe las matrices objetivo A y su matriz izquierda W\n",
    "  Calcula la resolución iterativa de la minimización según el paper\n",
    "  y obtenemos la minimización de H a partir de W\n",
    "  Retorna las matrices W, H de las descomposición\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A)\n",
    "\n",
    "  # resolvemos por minimos cuadrados\n",
    "  H = np.linalg.solve(np.dot(np.transpose(W), W), np.dot(np.transpose(W), A))\n",
    "\n",
    "  # Separamos en columnas\n",
    "  w1, w2 = W[:, 0], W[:, 1]\n",
    "  beta1, beta2 = np.linalg.norm(w1), np.linalg.norm(w2)\n",
    "\n",
    "  # normalizamos\n",
    "  u, v = np.dot(np.transpose(A), w1)/beta1, np.dot(np.transpose(A), w2)/beta2\n",
    "\n",
    "  for j in range(n):\n",
    "    # Para cada vector determinamos si cumple con la solucion\n",
    "    retorno_j = np.zeros(2)\n",
    "    if (H[:, j] >= 0).all():\n",
    "      continue\n",
    "    elif u[j]*beta1 >= v[j]*beta2:\n",
    "      retorno_j[0] = u[j]\n",
    "    else:\n",
    "      retorno_j[1] = v[j]\n",
    "    H[:, j] = retorno_j\n",
    "  return W, H\n",
    "\n",
    "def NMF_rank2(A, W=None, H=None, k=2, **kwargs):\n",
    "  \"\"\"\n",
    "  Recibe la matriz objetivo y matrices iniciales\n",
    "  Se realiza dos veces la minimización primero para H\n",
    "  y luego para W\n",
    "  Retorna la descomposición W, H de baja calidad\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A)\n",
    "\n",
    "  # Iniciamos las matrices\n",
    "  if W is None:\n",
    "    W = np.random.rand(m, k)\n",
    "\n",
    "  if H is None:\n",
    "    H = np.zeros((k, n))\n",
    "  \n",
    "  # Realizamos las minimizaciones\n",
    "  W, H = rank2(A, W)\n",
    "  HT, WT = rank2(np.transpose(A), np.transpose(H))\n",
    "  # Retornamos los valores que resultaron minimizados\n",
    "  return np.transpose(WT), np.transpose(HT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu4Uze6DOUOW"
   },
   "outputs": [],
   "source": [
    "def calculo_NMF(A, max_iteraciones=15, k=2, W=None, H=None, error=0.5):\n",
    "  \"\"\"\n",
    "  Recibe la matriz objetivo A, dimension k,\n",
    "  máximo de iteraciones y matrices iniciales\n",
    "  Realiza de forma recursiva la aplicación de rank-2\n",
    "  para así obtener una mejor aproximación\n",
    "  Retorna los elementos W, H que aproximan A\n",
    "  al alcanzar una cota de error o superar el maximo\n",
    "  \"\"\"\n",
    "  # Inicializamos las matrices\n",
    "  m, n = np.shape(A)\n",
    "  if W is None:\n",
    "    W = np.random.rand(m, k)\n",
    "\n",
    "  for i in range(max_iteraciones):\n",
    "    W, H = rank2(A, W)\n",
    "    HT, WT = rank2(np.transpose(A), np.transpose(H))\n",
    "    W, H = np.transpose(WT), np.transpose(HT)\n",
    "    if (np.linalg.norm(A - np.dot(W, H))) < error: break\n",
    "  return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2AEFL66POis"
   },
   "outputs": [],
   "source": [
    "def normalizar_descomposicion(W, H):\n",
    "  \"\"\"\n",
    "  Normaliza las columnas de W y pondera respectivamente\n",
    "  las filas de H para el resultado esperado\n",
    "  \"\"\"\n",
    "\n",
    "  for j in range(2):\n",
    "    norma = np.linalg.norm(W[:, j])\n",
    "    W[:, j] = W[:, j]/norma\n",
    "    H[j, :] = H[j, :]*norma\n",
    "  return W, H\n",
    "\n",
    "\n",
    "def calcular_descomposicion(A_matrix, max_iteraciones=15, max_intentos=10):\n",
    "  \"\"\"\n",
    "  Recibe matriz objetivo, cantidad maxima iteraciones e intentos de calcular\n",
    "  Calcula la descomposición rank-2 de forma reiterativa\n",
    "  Si el i-esimo intento alcanza la cota\n",
    "  se retorna la descomposición W, H\n",
    "  \"\"\"\n",
    "  salida, excepcion = False, False\n",
    "  for i in range(max_intentos):\n",
    "    try:\n",
    "      W, H = calculo_NMF(A_matrix, max_iteraciones, k=2, W=None, H=None)\n",
    "      error = np.linalg.norm(np.dot(W, H) - A_matrix)\n",
    "      if error < 60:\n",
    "        salida = True\n",
    "    except:\n",
    "      excepcion = True\n",
    "    else:\n",
    "      if not excepcion and salida:\n",
    "        return normalizar_descomposicion(W, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_t-3DmOnyv3"
   },
   "source": [
    "### Estructura jerárquica\n",
    "\n",
    "* Para ir generando una estructura jerárquica debemos poder determinar cómo hacer split de los datos\n",
    "\n",
    "  * Necesitamos determinar donde conviene más separar los datos\n",
    "  * Para esto necesitamos una métrica\n",
    "    * Utilizaremos la misma distribución de las palabras que entregan las columnas de la matriz $W$ de la descomposición\n",
    "\n",
    "* Además debemos saber si el split que vamos a hacer conviene, pues deben ser operaciones optimas\n",
    "\n",
    "* El dividir y conquistar los datos nos permitirá realizar el algoritmo de forma recursiva\n",
    "\n",
    "  * Aplicaremos NMF haremos split de los datos\n",
    "  * A estos dos hijos de datos les aplicaremos NMF\n",
    "  * Continuaremos hasta alcanzar cierto objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVZ4E3og0I0E"
   },
   "outputs": [],
   "source": [
    "def idx_plbs(arreglo):\n",
    "  \"\"\"\n",
    "  Recibe un arreglo de palabras\n",
    "  Genera un diccionario con los detalles de la palabra\n",
    "  retornando una lista ordenada según relevancia\n",
    "  \"\"\"\n",
    "  largo = len(arreglo)\n",
    "  retorno = list({'word': i, 'value': arreglo[i]} for i in range(largo))\n",
    "  retorno = sorted(retorno, key=lambda x: x['value'], reverse=True)\n",
    "\n",
    "  for i in range(largo):\n",
    "    retorno[i]['id'] = i\n",
    "  return retorno\n",
    "\n",
    "def generar_arrays(array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos para poder dividir\n",
    "  Retorna los arreglos ordenados según relevancia de sus palabras\n",
    "  \"\"\"\n",
    "  return idx_plbs(array_N), idx_plbs(array_L), idx_plbs(array_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iVS2CBb3-YI"
   },
   "outputs": [],
   "source": [
    "def factor_descuento(word, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos y la palabra para la cual\n",
    "  se va a calcular su descuento\n",
    "  Retorna el descuento de la palabra\n",
    "  \"\"\"\n",
    "\n",
    "  fi_L = next(x for x in array_L if x['word'] == word)\n",
    "  fi_R = next(x for x in array_R if x['word'] == word)  \n",
    "  return np.log2(len(array_L) - max(fi_L['id'], fi_R['id']) + 1)\n",
    "\n",
    "\n",
    "def ganancia_palabra(word, array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos y la palabra de la que se quiere obtener su ganancia\n",
    "  Retorna la ganancia de la palabra\n",
    "  \"\"\"\n",
    "  \n",
    "  descuento = factor_descuento(word, array_L, array_R)\n",
    "  elemento = next(x for x in array_N if x['word'] == word)\n",
    "  return np.log2(len(array_L) - elemento['id'] + 1)/descuento\n",
    "\n",
    "\n",
    "def ganancias(array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Calcula la ganancia del arreglo\n",
    "  Retorna el arreglo de las ganancias y ordenada según ganancia\n",
    "  \"\"\"\n",
    "  retorno = list()\n",
    "  for word in range(len(array_N)):\n",
    "    gan_actual = ganancia_palabra(word, array_N, array_L, array_R)\n",
    "    retorno.append({'palabra': word, 'ganancia': gan_actual})\n",
    "  \n",
    "  return retorno, sorted(retorno, key=lambda x: x['ganancia'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkS5BLqhGJuf"
   },
   "outputs": [],
   "source": [
    "def MDCG(gan_array):\n",
    "  \"\"\"\n",
    "  Calculo de MDCG según el array que se entregue\n",
    "  Retorna el valor de ganancia\n",
    "  \"\"\"\n",
    "  largo = len(gan_array)\n",
    "  elementos = list(gan_array[i]['ganancia']/np.log2(i+1) for i in range(1, largo))\n",
    "  return gan_array[0]['ganancia'] + sum(elementos)\n",
    "\n",
    "\n",
    "def mNDCG(gan_array, gan_sort):\n",
    "  \"\"\"\n",
    "  Calculo del puntaje a través de los arrays listos\n",
    "  \"\"\"\n",
    "  return MDCG(gan_array)/MDCG(gan_sort)\n",
    "\n",
    "\n",
    "def puntaje(f_N, f_L, f_R):\n",
    "  \"\"\"\n",
    "  Calcula el puntaje de la descomposición NMF actual\n",
    "  Retorna el valor que nos ayuda a decidir\n",
    "  \"\"\"\n",
    "  gan, gan_sort = ganancias(*generar_arrays(f_N, f_L, f_R))\n",
    "  return mNDCG(gan, gan_sort)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42-U4DSMNT_b"
   },
   "outputs": [],
   "source": [
    "def elem_puntaje(A_matrix, L_matrix, R_matrix):\n",
    "  \"\"\"\n",
    "  Calcula la descomposición NMF de A (nodo)\n",
    "  y de sus posibles hijos\n",
    "  Retorna los elementos necesarios para determinar si conviene\n",
    "  \"\"\"\n",
    "\n",
    "  condicion = False\n",
    "  while not condicion:\n",
    "    try:\n",
    "      W, H = calcular_descomposicion(A_matrix)\n",
    "      WL, HL = calcular_descomposicion(L_matrix)\n",
    "      WR, HR = calcular_descomposicion(R_matrix)\n",
    "      condicion = True\n",
    "    except:\n",
    "      condicion = False\n",
    "    else:\n",
    "      if condicion:\n",
    "        return W, H, WL, HL, WR, HR\n",
    "\n",
    "def calculo_puntajes(W, H, WL, HL, WR, HR, i):  \n",
    "  \"\"\"\n",
    "  Calcula el puntaje de los hijos del nodo\n",
    "  a partir de los \n",
    "  \"\"\"\n",
    "  X = W[:, i].copy()\n",
    "\n",
    "  puntaje_N1 = puntaje(X, WL[:, 0], WL[:, 1])\n",
    "  puntaje_N2 = puntaje(X, WR[:, 0], WR[:, 1])\n",
    "\n",
    "  return puntaje_N1, puntaje_N2\n",
    "\n",
    "\n",
    "def puntajes_hijos(A, L, R):\n",
    "  \"\"\"\n",
    "  Genera el calculo del puntaje a partir de los\n",
    "  elementos necesario a partir del nodo\n",
    "  \"\"\"\n",
    "  # W, H, WL, HL, WR, HR = elem_puntaje(A, L, R)\n",
    "  return calculo_puntajes(*elem_puntaje(A, L, R), 0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjhkLjQoaOVE"
   },
   "outputs": [],
   "source": [
    "def agregar_columna(A, columna):\n",
    "  \"\"\"\n",
    "  Agrega columna a la matriz A sin importar su contenido\n",
    "  Retorna la matriz con la columna añadida\n",
    "  \"\"\"\n",
    "  if A is None:\n",
    "    A = np.zeros((len(columna), 1))\n",
    "    A[:, 0] = columna\n",
    "  else:\n",
    "    A = np.column_stack((A,columna))\n",
    "  return A\n",
    "\n",
    "\n",
    "def split_matrix(A_matrix, W, H, columnas):\n",
    "  \"\"\"\n",
    "  Separación de la matriz por contenido\n",
    "  Retorna la separación en dos matrices\n",
    "  \n",
    "  col_docs:\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A_matrix)\n",
    "\n",
    "  A1, A2 = None, None\n",
    "  \n",
    "  retorno_A1 = list()\n",
    "  retorno_A2 = list()\n",
    "\n",
    "  for j in range(n):\n",
    "    if H[0][j] > H [1][j]:\n",
    "      A1 = agregar_columna(A1, A_matrix[:, j])\n",
    "      retorno_A1.append(columnas[j])\n",
    "    else:\n",
    "      A2 = agregar_columna(A2, A_matrix[:, j])\n",
    "      retorno_A2.append(columnas[j])\n",
    "\n",
    "  if A1.shape[1] >= A2.shape[1]:\n",
    "    return A1, A2, retorno_A1, retorno_A2\n",
    "  return A2, A1, retorno_A2, retorno_A1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhzFR8xYf5fq"
   },
   "source": [
    "# Parte final\n",
    "\n",
    "Vamos a generar un arreglo que contenga la estructura de nuestro arbol\n",
    "* Será un ejemplo sencillo por lo que usaremos pocos nodos\n",
    "* Usamos un arreglo para los nodos generado\n",
    "* Retornaría este arreglo que describe la estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fbk-HUhf4-I"
   },
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "\n",
    "numero_nodos = 7 # cantidad nodos para crear\n",
    "beta = 1.1 # diferencia de tamaño mínima que habrá entre los nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJgG4CuvgyXS"
   },
   "outputs": [],
   "source": [
    "def seleccionar_nodo(lista_nodos):\n",
    "  \"\"\"\n",
    "  Recibe el arreglo de los nodos de la estructura\n",
    "  Calcula cual nodo es conveniente separar y lo retorna\n",
    "  \"\"\"\n",
    "  if len(lista_nodos) == 1:\n",
    "    return lista_nodos[0]\n",
    "  lista_nodos = sorted(lista_nodos,\n",
    "                       key = lambda i: i['puntaje'],\n",
    "                       reverse=True)\n",
    "  return lista_nodos[1]\n",
    "\n",
    "def menor_puntaje(lista_nodos, puntaje_N2):\n",
    "  \"\"\"\n",
    "  Determina si el puntaje actual es el\n",
    "  menor comparando con todos los nodos\n",
    "  Retorna bool si conviene hacer split a ese nodo\n",
    "  \"\"\"\n",
    "  for elemento in lista_nodos:\n",
    "    if elemento['puntaje'] <= puntaje_N2:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdxgV1Pf1S3p"
   },
   "outputs": [],
   "source": [
    "def palabras_columna(W, i):\n",
    "  \"\"\"\n",
    "  Genera el arreglo de las palabras de la columna i\n",
    "  Retorna arreglo diccionarios con los datos ordenados\n",
    "  \"\"\"\n",
    "\n",
    "  entradas = ['idx', 'value']\n",
    "  distribucion, retorno = W[:, i], list()\n",
    "  for item in enumerate(distribucion):\n",
    "    retorno.append(dict(zip(entradas, item)))\n",
    "  return sorted(retorno, key=lambda i: i['value'], reverse=True)\n",
    "\n",
    "\n",
    "def encontrar_significado(arreglo):\n",
    "  \"\"\"\n",
    "  Recibe el arreglo de indices de palabras\n",
    "  Retorna los elementos con atributo word que es el significado\n",
    "  \"\"\"\n",
    "  for i in range(len(arreglo)):\n",
    "    arreglo[i]['word'] = index_to_word[arreglo[i]['idx'] + 4]\n",
    "  return arreglo\n",
    "\n",
    "def palabras_destacadas(W, cantidad=3):\n",
    "  \"\"\"\n",
    "  Selecciona las palabras más relevantes\n",
    "  de la matriz W\n",
    "  Retorna un arreglo con astas palabras\n",
    "  \"\"\"\n",
    "  n = int(np.round(cantidad/2))+1\n",
    "  retorno = encontrar_significado(palabras_columna(W, 0)[:n])\n",
    "  retorno.extend(encontrar_significado(palabras_columna(W, 1)[:n]))\n",
    "  return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQzkWiA8f2yg"
   },
   "outputs": [],
   "source": [
    "def jerarquizacion(A_matrix):\n",
    "  \"\"\"\n",
    "  Genera la estructura de jerarquía realizando\n",
    "  descomposiciones NMF de forma recursiva\n",
    "  Retorna la estructura \n",
    "  \"\"\"\n",
    "\n",
    "  outliner = None\n",
    "  lista_nodos = list()\n",
    "\n",
    "  primer_nodo = {\n",
    "    'id': 1,\n",
    "    'parent': None,\n",
    "    'matrix': A_matrix,\n",
    "    'puntaje': 1,\n",
    "    'shape': A_matrix.shape,\n",
    "    'columnas': list(i for i in range(A_matrix.shape[1]))\n",
    "  }\n",
    "\n",
    "  lista_nodos.append(primer_nodo)\n",
    "\n",
    "  for i in range(1, numero_nodos, 2):\n",
    "    M = seleccionar_nodo(lista_nodos)\n",
    "    M['W'], M['H'] = calcular_descomposicion(M['matrix'])\n",
    "    #M['W'], M['H'] = W, H\n",
    "    \n",
    "    N1, N2, cols_N1, cols_N2 = split_matrix(M['matrix'],\n",
    "                                            M['W'],\n",
    "                                            M['H'],\n",
    "                                            M['columnas'])\n",
    "    \n",
    "    puntaje_N1, puntaje_N2 = puntajes_hijos(M['matrix'], N1, N2)\n",
    "    \n",
    "    N1_nodo = {\n",
    "    'id': i+1,\n",
    "    'parent': M['id'],\n",
    "    'matrix': N1,\n",
    "    'puntaje': puntaje_N1,\n",
    "    'shape': N1.shape,\n",
    "    'hijos': None,\n",
    "    'columnas': cols_N1\n",
    "    }\n",
    "\n",
    "    N2_nodo = {\n",
    "    'id': i+2,\n",
    "    'parent': M['id'],\n",
    "    'matrix': N2,\n",
    "    'puntaje': puntaje_N2,\n",
    "    'shape': N2.shape,\n",
    "    'hijos': None,\n",
    "    'columnas': cols_N2\n",
    "    }\n",
    "\n",
    "    M['hijos'] = [i+1, i+2, ]\n",
    "\n",
    "    lista_nodos.append(N1_nodo)\n",
    "    lista_nodos.append(N2_nodo)\n",
    "\n",
    "  return obtener_palabras_destacadas(lista_nodos, cantidad=10)\n",
    "  #return lista_nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IPf2qvqkVBtc",
    "outputId": "75ee4779-3c94-44ca-9517-42be9ffb01e2"
   },
   "outputs": [],
   "source": [
    "def matriz_W_lista(lista_nodos):\n",
    "  for nodo in lista_nodos:\n",
    "    if 'W' not in nodo.keys():\n",
    "      nodo['W'], nodo['H'] = calcular_descomposicion(nodo['matrix'])\n",
    "  return lista_nodos\n",
    "\n",
    "\n",
    "def limpiar_lista(lista_nodos):\n",
    "  elementos = ['matrix', 'W', 'H']\n",
    "  new_list = [{k: v for k, v in d.items() if k not in elementos} for d in lista_nodos]\n",
    "  return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_arbol = jerarquizacion(A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUj8shzZ9B9J"
   },
   "outputs": [],
   "source": [
    "def obtener_palabras_destacadas(lista_arbol, cantidad=10):\n",
    "  for nodo in lista_arbol:\n",
    "    if nodo['matrix'].shape[1] == 1:\n",
    "      nodo['W'] = nodo['matrix']\n",
    "    elif 'W' not in nodo.keys():\n",
    "      nodo['W'], nodo['H'] = calcular_descomposicion(nodo['matrix'])\n",
    "    nodo['destacadas'] = palabras_destacadas(nodo['W'], cantidad)\n",
    "    nodo['destacadas'] = palabras_relevantes(nodo['destacadas'])\n",
    "  return lista_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_arbol = obtener_palabras_destacadas(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OiuTMnkiOfR"
   },
   "outputs": [],
   "source": [
    "#lista_arbol = limpiar_lista(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicos_relevantes(y_data, columnas, mapping):\n",
    "  counts = dict()\n",
    "  for col in columnas:\n",
    "    if str(y_data[col]) in counts:\n",
    "      counts[str(y_data[col])] += 1\n",
    "    else:\n",
    "      counts[str(y_data[col])] = 1\n",
    "      \n",
    "  keys = ['label', 'frequency']\n",
    "\n",
    "  auxiliar = list(dict(zip(keys, tupla)) for tupla in counts.items())\n",
    "\n",
    "  labels = sorted(auxiliar, key = lambda i: i['frequency'], reverse=True)\n",
    "  \n",
    "  for elemento in labels:\n",
    "    elemento['label'] = int(elemento['label'])\n",
    "    elemento['label_name'] = mapping[elemento['label']]\n",
    "  return labels[:3]\n",
    "\n",
    "def palabras_relevantes(palabras):\n",
    "  palabras = dict((palabra['word'], palabra['frequency']) for palabra in palabras)\n",
    "  return dict(sorted(palabras.items(), key=operator.itemgetter(1), reverse=True))[:5]\n",
    "  #return list(x['word'] for x in palabras[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presentar_nodos(lista_arbol):\n",
    "  for objeto in lista_arbol:\n",
    "    print(f\"Nodo {objeto['id']}\")\n",
    "    print(f\"  parent: {objeto['parent']} - leafs {objeto['hijos']}\")\n",
    "    topicos = topicos_relevantes(y_data, objeto['columnas'], mapping)\n",
    "    for topico in topicos:\n",
    "      print(topico)\n",
    "    print(\"\")\n",
    "    palabras = palabras_relevantes(objeto['destacadas'])\n",
    "    frase = \"\"\n",
    "    for w in palabras:\n",
    "      if frase:\n",
    "        frase += \" / \"\n",
    "      frase += w\n",
    "    print(frase)\n",
    "    print(\"----------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_arbol = obtener_palabras_destacadas(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodo 1\n",
      "  parent: None - leafs [2, 3]\n",
      "{'label': 4, 'frequency': 26, 'label_name': 'acq'}\n",
      "{'label': 1, 'frequency': 26, 'label_name': 'grain'}\n",
      "{'label': 0, 'frequency': 26, 'label_name': 'cocoa'}\n",
      "\n",
      "mln / said / a / 3 / and\n",
      "----------------------------------------\n",
      "\n",
      "Nodo 2\n",
      "  parent: 1 - leafs None\n",
      "{'label': 4, 'frequency': 22, 'label_name': 'acq'}\n",
      "{'label': 0, 'frequency': 20, 'label_name': 'cocoa'}\n",
      "{'label': 2, 'frequency': 18, 'label_name': 'veg-oil'}\n",
      "\n",
      "said / and / a / 3 / vs\n",
      "----------------------------------------\n",
      "\n",
      "Nodo 3\n",
      "  parent: 1 - leafs [6, 7]\n",
      "{'label': 3, 'frequency': 15, 'label_name': 'earn'}\n",
      "{'label': 1, 'frequency': 9, 'label_name': 'grain'}\n",
      "{'label': 6, 'frequency': 9, 'label_name': 'copper'}\n",
      "\n",
      "000 / as / have / per / which\n",
      "----------------------------------------\n",
      "\n",
      "Nodo 4\n",
      "  parent: 3 - leafs None\n",
      "{'label': 1, 'frequency': 9, 'label_name': 'grain'}\n",
      "{'label': 6, 'frequency': 9, 'label_name': 'copper'}\n",
      "{'label': 2, 'frequency': 7, 'label_name': 'veg-oil'}\n",
      "\n",
      "with / or / billion / its / 7\n",
      "----------------------------------------\n",
      "\n",
      "Nodo 5\n",
      "  parent: 3 - leafs None\n",
      "{'label': 3, 'frequency': 15, 'label_name': 'earn'}\n",
      "\n",
      "than / 000 / be / more / but\n",
      "----------------------------------------\n",
      "\n",
      "Nodo 6\n",
      "  parent: 3 - leafs None\n",
      "{'label': 3, 'frequency': 15, 'label_name': 'earn'}\n",
      "{'label': 6, 'frequency': 5, 'label_name': 'copper'}\n",
      "{'label': 1, 'frequency': 3, 'label_name': 'grain'}\n",
      "\n",
      "000 / as / have / per / which\n",
      "----------------------------------------\n",
      "\n",
      "Nodo 7\n",
      "  parent: 3 - leafs None\n",
      "{'label': 1, 'frequency': 6, 'label_name': 'grain'}\n",
      "{'label': 0, 'frequency': 5, 'label_name': 'cocoa'}\n",
      "{'label': 5, 'frequency': 4, 'label_name': 'wheat'}\n",
      "\n",
      "said / 3 / a / mln / reuter\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#presentar_nodos(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reuters.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
