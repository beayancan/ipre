{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FOnO1SD-pzs"
   },
   "source": [
    "# NMF Rank-2 con dataset Reuters\n",
    "\n",
    "Autor: Benjamin Ayancán, PUC Chile\n",
    "Tutor: Denis Parra, PUC Chile\n",
    "\n",
    "En el siguiente notebook desarrollaremos un ejemplo de cómo poder generar una descomposición jerarquica a través del algoritmo de rango bajo NMF rank-2.\n",
    "\n",
    "* Para este tutorial usaremos el dataset de noticias Reuters que nos entrega la libería `keras`\n",
    "\n",
    "* Los aspectos teoricos y detalles del algoritmo son abordados en el  siguiente [notebook de Observablehq](https://observablehq.com/@beayancan/descomposicion-jerarquica)\n",
    "\n",
    "* Para hacer más pedagógico el ejemplo se va a reducir tanto la cantidad de datos (filas) como la cantidad de features (columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLET-ev4s9Rp"
   },
   "source": [
    "---\n",
    "\n",
    "## Configuración\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "--> Si lo estás ejecutando en un `jupyter notebook` debes instalar las siguientes librerías\n",
    "\n",
    "```py\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "```\n",
    "\n",
    "--> Si lo estás ejecutando en `colab`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEb5CzWsY-xO"
   },
   "outputs": [],
   "source": [
    "# Chequeamos que nuestro soporte no tenga problemas\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hb3X252TY0H2",
    "outputId": "1bb6d096-4898-4c6d-995a-462ac45e6fc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importamos las liberías que vamos a utilizar\n",
    "# herramientas y el dataset\n",
    "\n",
    "import os, sys\n",
    "import keras\n",
    "import statistics\n",
    "import collections\n",
    "import numpy as np\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPD06Xvdtbp7"
   },
   "source": [
    "---\n",
    "\n",
    "## Reuters\n",
    "\n",
    "#### ¿Por qué usar esta librería?\n",
    "\n",
    "Reuters es un repositorio de documentos que podemos utilizar a través de `keras` o bien descargarlo en su [página web](http://konect.cc/networks/gottron-reuters/). Esta posee las siguientes características\n",
    "\n",
    "* Son un conjunto de 11.228 noticias, etiquetados en 46 tópicos.\n",
    "\n",
    "\n",
    "* Está preprocesado según un ranking de palabras de un volabulario, es decir su representación es a través de las posiciones en el ranking de las palabras de un documento\n",
    "* Posee funciones sencillas que nos ayudan a manejar cómo representar los documentos sin gastar mucho tiempo en su preprocesamiento\n",
    "* Se enfoca en el contenido de un documento, las palabras que lo representan, en vez del mensaje que este entregue\n",
    "\n",
    "---\n",
    "\n",
    "#### Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBBfF4DIuHC-"
   },
   "outputs": [],
   "source": [
    "# PARAMETROS\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters/load_data\n",
    "\n",
    "# Cantidad de palabras significativas del vocabulario a usar\n",
    "\n",
    "# num_words = None # incluirlas todas\n",
    "num_words = 100 # solo tomaremos las 100 primeras palabras\n",
    "skip_top = 0 # palabras que no consideraremos\n",
    "\n",
    "# máximo N° de palabras para representar a un documento\n",
    "max_len = None # todas\n",
    "# max_len = 50\n",
    "\n",
    "# Porcentaje de palabras para usar en el test set\n",
    "test_split = 0.025 # train set: 97.5%, test set: 2.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MPNg4lWueWs9",
    "outputId": "cb6c810e-43e2-49e0-9614-3cee8e1a852c"
   },
   "outputs": [],
   "source": [
    "# Cargamos los de datos de clasificación de noticias de Reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words,\n",
    "                                                         maxlen=max_len,\n",
    "                                                         test_split=test_split,\n",
    "                                                         skip_top=skip_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "xrzJdAjwWnvA",
    "outputId": "cf86be6d-256b-4a1c-95f6-8143ea984288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train set: (10947,)\n",
      "Tamaño test set: (281,)\n",
      "Cantidad clases: 46\n"
     ]
    }
   ],
   "source": [
    "# Revisamos cómo fueron cargados los datos\n",
    "\n",
    "# y_train, y_test contendrán los labels de las clases\n",
    "\n",
    "num_clases = max(y_train) + 1\n",
    "\n",
    "print(f'Tamaño train set: {x_train.shape}')\n",
    "print(f'Tamaño test set: {x_test.shape}')\n",
    "print(f'Cantidad clases: {num_clases}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tW0E5KIwiCi"
   },
   "source": [
    "### Qué es lo que contienen\n",
    "* Cada elemento del set contiene los índices de las palabras más utilizadas por un documento\n",
    "\n",
    "* Las palabras están ordenadas según su frecuencia de aparición\n",
    "* Además cada documento pertenece a un tópico en especifico\n",
    "* Notar por el `x_train.shape` que las representaciones no tienen un largo especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "2SqXKHd1gxs8",
    "outputId": "c23a4019-c6e0-43ef-e894-2c6e51c8eaf7"
   },
   "outputs": [],
   "source": [
    "# Mostremos algunos ejemplos\n",
    "# for i in range(1,15, 3):\n",
    "#   print(f'Doc: {i},  largo: {len(x_test[i])}, clase {y_test[i]}')\n",
    "#   print(f'   contenido: {x_test[i]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "colab_type": "code",
    "id": "TmYUZB3gtZBd",
    "outputId": "f60e3dcb-7302-4b79-fc36-f6a169c9616c"
   },
   "outputs": [],
   "source": [
    "mapping = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "           'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "           'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "           'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "           'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']\n",
    "\n",
    "train_count = collections.Counter(y_train)\n",
    "test_count = collections.Counter(y_test)\n",
    "total_words = [statistics.mean([len(e) for e in x_train[y_train.flatten() == i]]) for i in range(46)]\n",
    "\n",
    "# print(\"         Las clases y sus estadísticas\")\n",
    "# print(\"{:4s} {:20s} {:5s}  {:5s} {:7s}\".format(\"Idx\",\"Clase\", \"train\", \"test\", \"Palabras\"))\n",
    "# for i in range(46):\n",
    "#    print(\"{:5d} {:20s} {:5d} {:5d}   {:6.2f}\".format(i,mapping[i], train_count[i], test_count[i], total_words[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1QfRta5-2UO"
   },
   "source": [
    "### Qué es lo que representan\n",
    "* Solo tenemos los índices, pero ¿de qué?\n",
    "  * Son la posición rankeada de la palabra\n",
    "* Usamos la indexación del vocabulario del dataset para identificar la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Ses2uu-X6EiC",
    "outputId": "6579106d-530b-4ea8-ff0e-ef9581941f4f"
   },
   "outputs": [],
   "source": [
    "# Tenemos el vocabulario con las palabras y sus indices\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# Generamos un diccionario con el contenido\n",
    "index_to_word = { value+3 : key for key, value in word_index.items() }\n",
    "\n",
    "# Indices reservados\n",
    "index_to_word[0] = '-PAD-'   # 0: carpeta\n",
    "index_to_word[1] = '-START-' # 1: inicio secuencia\n",
    "index_to_word[2] = '-UNK-'   # 2: elemento no encontrado\n",
    "\n",
    "len_index = len(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtkSV7UNPdc9"
   },
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "* Para poder realizar los calculos, necesitamos\n",
    "  * Una estructura regular de datos\n",
    "  * Que cada documento posea un mismo largo\n",
    "\n",
    "* Pasaremos primero los datos a una menor dimensión reduciendo las palabras y eliminando lo innecesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjKzIVgY2M2U"
   },
   "outputs": [],
   "source": [
    "# Primero eliminaremos las referencias a elementos que no se encuentran\n",
    "# dentro de las 1000 palabras más usadas en el vocabulario\n",
    "# ademas de las entradas reservadas\n",
    "\n",
    "  # Eliminamos\n",
    "  # 0: '-PAD-'\n",
    "  # 1: '-START-'\n",
    "  # 2: '-UNK-'\n",
    "  # 12: '3'\n",
    "  # 17: 'reuter'\n",
    "\n",
    "def filtrar_relevante(arreglo, por_eliminar=[0,1,2]):\n",
    "  \"\"\"\n",
    "  Borra las palabras que pertenecen a los indices del array por_eliminar\n",
    "  \"\"\"\n",
    "  return list(filter(lambda x: x not in por_eliminar, arreglo))\n",
    "\n",
    "def eliminar_reservadas(x_array):\n",
    "  \"\"\"\n",
    "  Eliminamos las entradas reservadas y entradas inutiles\n",
    "  retorna el contenido homogeneo del doc\n",
    "  \"\"\"\n",
    "  por_eliminar = [0,1,2,12,17]\n",
    "  largo_test, = x_array.shape\n",
    "  for i in range(largo_test):\n",
    "    x_array[i] = filtrar_relevante(x_array[i], por_eliminar)\n",
    "  return x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVifRE33sxqN"
   },
   "outputs": [],
   "source": [
    "# Para hacer un ejemplo más sencillo de entender\n",
    "# Selecionaremos solo las primeras 7 clases\n",
    "\n",
    "def reducir_labels(data_array, labels, k=7):\n",
    "  \"\"\"\n",
    "  Filtramos los documentos que pertenezcan a las primeras k clases\n",
    "  Retornamos el arreglo con los documentos y sus correspondientes labels\n",
    "  \"\"\"\n",
    "\n",
    "  retorno, retorno_labels = list(), list()\n",
    "  for i in range(len(data_array)):\n",
    "    if labels[i] < k:\n",
    "      retorno.append(data_array[i])\n",
    "      retorno_labels.append(labels[i])\n",
    "  return np.array(retorno), retorno_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5NPalNU7tAXU",
    "outputId": "68f3ec51-ac70-4414-d91a-ae128e5848f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173,)\n"
     ]
    }
   ],
   "source": [
    "x_test = eliminar_reservadas(x_test)\n",
    "x_data, y_data = reducir_labels(x_test, y_test, k=7)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "MbLfYLj3vI2m",
    "outputId": "f4b03fcf-6dea-4458-e898-871d68b0ea4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc: 1,  Largo: 55, Clase 3\n",
      " [71, 8, 25, 10, 5, 68, 13, 67, 5, 4, 80, 6, 5, 93, 16, 8, 4, 6, 68, 5, 10, 67, 5, 80, 5, 28, 42, 96, 5, 15, 8, 4, 91, 30, 92, 83, 4, 5, 58, 5, 10, 13, 28, 20, 5, 4, 80, 4, 49, 24, 16, 40, 6, 23, 10] \n",
      " inc said its a of one for share of the stock to of april it said the to one of a share of stock of at an price of dlrs said the may be after 10 the of or of a for at pct of the stock the company that it has to is a \n",
      "\n",
      "Doc: 4,  Largo: 71, Clase 3\n",
      " [53, 19, 15, 14, 26, 39, 59, 11, 14, 32, 11, 86, 19, 35, 14, 19, 32, 35, 53, 15, 14, 32, 15, 39, 11, 14, 70, 11, 86, 63, 35, 14, 44, 35, 89, 9, 68, 92, 5, 11, 15, 58, 26, 10, 67, 13, 7, 4, 98, 5, 42, 7, 48, 39, 27, 26, 10, 67, 13, 7, 21, 89, 34, 72, 35, 15, 50, 49, 8, 34, 10] \n",
      " shr 1 dlrs vs cts net 6 mln vs 2 mln revs 1 billion vs 1 2 billion shr dlrs vs 2 dlrs net mln vs 0 mln revs 8 billion vs 5 billion 1987 and one after of mln dlrs or cts a share for in the quarter of an in 1986 net by cts a share for in on 1987 was 9 billion dlrs which company said was a \n",
      "\n",
      "Doc: 7,  Largo: 50, Clase 3\n",
      " [53, 46, 68, 14, 74, 26, 39, 46, 70, 11, 14, 74, 18, 86, 59, 11, 14, 11, 29, 53, 46, 32, 15, 14, 46, 32, 15, 39, 46, 63, 47, 11, 14, 46, 61, 72, 11, 86, 11, 14, 32, 11, 48, 29, 68, 5, 19, 32, 11, 15] \n",
      " shr loss one vs profit cts net loss 0 mln vs profit 000 revs 6 mln vs mln year shr loss 2 dlrs vs loss 2 dlrs net loss 8 4 mln vs loss 7 9 mln revs mln vs 2 mln 1986 year one of 1 2 mln dlrs \n",
      "\n",
      "Doc: 10,  Largo: 12, Clase 3\n",
      " [10, 49, 25, 99, 5, 44, 26, 93, 6, 5, 93, 19] \n",
      " a company its first of 5 cts april to of april 1 \n",
      "\n",
      "Doc: 13,  Largo: 4, Clase 3\n",
      " [26, 14, 26, 94] \n",
      " cts vs cts march \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostremos lo que contiene\n",
    "for i in range(1,15, 3):\n",
    "  print(f'Doc: {i},  Largo: {len(x_data[i])}, Clase {y_data[i]}')\n",
    "  print(f' {x_data[i]}', '\\n', ' '.join([index_to_word[word] for word in x_data[i]]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VV9CKo3L8Get"
   },
   "source": [
    "### Pasar los datos a matriz doc-term\n",
    "\n",
    "* Pasamos a una matriz $A \\in \\mathbb{R}^{m \\times n}$ donde $m$ es la cantidad de documentos y $n$ es la cantidad de palabras del vocabulario\n",
    "* Pasaremos los datos a una representación de $\\{0, 1\\}$\n",
    "* Representando la entrada $A[i,j]$ la aparición en el $i$-ésimo documento la $j$-ésima palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ngXLKqz6etw"
   },
   "outputs": [],
   "source": [
    "# Importamos tokenizer para producirlo\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tkn = Tokenizer(num_words=num_words) # tamaño del vocabulario\n",
    "num_clases = max(y_data) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2pvAU85QIr6"
   },
   "outputs": [],
   "source": [
    "# Contruimos la matriz pasando los datos a binario\n",
    "\n",
    "x_data_bin = tkn.sequences_to_matrix(x_data, mode='binary')\n",
    "y_data_cat = to_categorical(y_data, num_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "mVCpasedQepb",
    "outputId": "568305d5-dfb3-4f3b-aa4c-6ff3dac0b70c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: (173, 100) \n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1.]\n",
      "\n",
      "Test Set: (173, 7)   (usaremos este) \n",
      " [0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los como queda la representacion\n",
    "\n",
    "entry = 10\n",
    "print(f'Train Set: {x_data_bin.shape} \\n {x_data_bin[entry]}\\n')\n",
    "print(f'Test Set: {y_data_cat.shape}   (usaremos este) \\n {y_data_cat[entry]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox3JNVrwQc2o"
   },
   "outputs": [],
   "source": [
    "# Siguiendo la interpretación del paper\n",
    "\n",
    "A_matrix = np.transpose(x_data_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTEMF7ZhSrYl"
   },
   "source": [
    "# NMF Jerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aa4N91wyStwu"
   },
   "source": [
    "* Ya tenemos unos datos preprocesados de forma ideal para nuestro trabajo\n",
    "* Realizaremos la secuencia de NMF jerárquico siguiendo el paper\n",
    "  * [Fast Rank-2 Nonnegative Matrix Factorization for Hierarchical Document Clustering](https://smallk.github.io/papers/hierNMF2.pdf)\n",
    "\n",
    "* Recordar que el objetivo es minimizar la siguiente operación\n",
    "  $$\\min_{W \\geq 0, H \\geq 0} ||A - WH||_2^{2}$$\n",
    "  * A través de la resolución de los subproblemas convexos\n",
    "    $$\\min_{H \\geq 0} ||A - WH||_2^{2}$$\n",
    "    $$\\min_{W \\geq 0} ||A^T - H^T W^T||_2^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NcwIIZe32N7"
   },
   "source": [
    "## NMF Rank-2\n",
    "\n",
    "* Usaremos el algoritmo Rank-2 para generar una estructura de árbol binario jerárquico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9slMc7UPuZPW"
   },
   "outputs": [],
   "source": [
    "def rank2(A, W):\n",
    "  \"\"\"\n",
    "  Recibe las matrices objetivo A y su matriz izquierda W\n",
    "  Calcula la resolución iterativa de la minimización según el paper\n",
    "  y obtenemos la minimización de H a partir de W\n",
    "  Retorna las matrices W, H de las descomposición\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A)\n",
    "\n",
    "  # resolvemos por minimos cuadrados\n",
    "  H = np.linalg.solve(np.dot(np.transpose(W), W), np.dot(np.transpose(W), A))\n",
    "\n",
    "  # Separamos en columnas\n",
    "  w1, w2 = W[:, 0], W[:, 1]\n",
    "  beta1, beta2 = np.linalg.norm(w1), np.linalg.norm(w2)\n",
    "\n",
    "  # normalizamos\n",
    "  u, v = np.dot(np.transpose(A), w1)/beta1, np.dot(np.transpose(A), w2)/beta2\n",
    "\n",
    "  for j in range(n):\n",
    "    # Para cada vector determinamos si cumple con la solucion\n",
    "    retorno_j = np.zeros(2)\n",
    "    if (H[:, j] >= 0).all():\n",
    "      continue\n",
    "    elif u[j]*beta1 >= v[j]*beta2:\n",
    "      retorno_j[0] = u[j]\n",
    "    else:\n",
    "      retorno_j[1] = v[j]\n",
    "    H[:, j] = retorno_j\n",
    "  return W, H\n",
    "\n",
    "def NMF_rank2(A, W=None, H=None, k=2, **kwargs):\n",
    "  \"\"\"\n",
    "  Recibe la matriz objetivo y matrices iniciales\n",
    "  Se realiza dos veces la minimización primero para H\n",
    "  y luego para W\n",
    "  Retorna la descomposición W, H de baja calidad\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A)\n",
    "\n",
    "  # Iniciamos las matrices\n",
    "  if W is None:\n",
    "    W = np.random.rand(m, k)\n",
    "\n",
    "  if H is None:\n",
    "    H = np.zeros((k, n))\n",
    "  \n",
    "  # Realizamos las minimizaciones\n",
    "  W, H = rank2(A, W)\n",
    "  HT, WT = rank2(np.transpose(A), np.transpose(H))\n",
    "  # Retornamos los valores que resultaron minimizados\n",
    "  return np.transpose(WT), np.transpose(HT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu4Uze6DOUOW"
   },
   "outputs": [],
   "source": [
    "def calculo_NMF(A, max_iteraciones=15, k=2, W=None, H=None, error=0.5):\n",
    "  \"\"\"\n",
    "  Recibe la matriz objetivo A, dimension k,\n",
    "  máximo de iteraciones y matrices iniciales\n",
    "  Realiza de forma recursiva la aplicación de rank-2\n",
    "  para así obtener una mejor aproximación\n",
    "  Retorna los elementos W, H que aproximan A\n",
    "  al alcanzar una cota de error o superar el maximo\n",
    "  \"\"\"\n",
    "  # Inicializamos las matrices\n",
    "  m, n = np.shape(A)\n",
    "  if W is None:\n",
    "    W = np.random.rand(m, k)\n",
    "\n",
    "  for i in range(max_iteraciones):\n",
    "    W, H = rank2(A, W)\n",
    "    HT, WT = rank2(np.transpose(A), np.transpose(H))\n",
    "    W, H = np.transpose(WT), np.transpose(HT)\n",
    "    if (np.linalg.norm(A - np.dot(W, H))) < error: break\n",
    "  return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2AEFL66POis"
   },
   "outputs": [],
   "source": [
    "def normalizar_descomposicion(W, H):\n",
    "  \"\"\"\n",
    "  Normaliza las columnas de W y pondera respectivamente\n",
    "  las filas de H para el resultado esperado\n",
    "  \"\"\"\n",
    "\n",
    "  for j in range(2):\n",
    "    norma = np.linalg.norm(W[:, j])\n",
    "    W[:, j] = W[:, j]/norma\n",
    "    H[j, :] = H[j, :]*norma\n",
    "  return W, H\n",
    "\n",
    "\n",
    "def calcular_descomposicion(A_matrix, max_iteraciones=15, max_intentos=10):\n",
    "  \"\"\"\n",
    "  Recibe matriz objetivo, cantidad maxima iteraciones e intentos de calcular\n",
    "  Calcula la descomposición rank-2 de forma reiterativa\n",
    "  Si el i-esimo intento alcanza la cota\n",
    "  se retorna la descomposición W, H\n",
    "  \"\"\"\n",
    "  salida, excepcion = False, False\n",
    "  for i in range(max_intentos):\n",
    "    try:\n",
    "      W, H = calculo_NMF(A_matrix, max_iteraciones, k=2, W=None, H=None)\n",
    "      error = np.linalg.norm(np.dot(W, H) - A_matrix)\n",
    "      if error < 60:\n",
    "        salida = True\n",
    "    except:\n",
    "      excepcion = True\n",
    "    else:\n",
    "      if not excepcion and salida:\n",
    "        return normalizar_descomposicion(W, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_t-3DmOnyv3"
   },
   "source": [
    "### Estructura jerárquica\n",
    "\n",
    "* Para ir generando una estructura jerárquica debemos poder determinar cómo hacer split de los datos\n",
    "\n",
    "  * Necesitamos determinar donde conviene más separar los datos\n",
    "  * Para esto necesitamos una métrica\n",
    "    * Utilizaremos la misma distribución de las palabras que entregan las columnas de la matriz $W$ de la descomposición\n",
    "\n",
    "* Además debemos saber si el split que vamos a hacer conviene, pues deben ser operaciones optimas\n",
    "\n",
    "* El dividir y conquistar los datos nos permitirá realizar el algoritmo de forma recursiva\n",
    "\n",
    "  * Aplicaremos NMF haremos split de los datos\n",
    "  * A estos dos hijos de datos les aplicaremos NMF\n",
    "  * Continuaremos hasta alcanzar cierto objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVZ4E3og0I0E"
   },
   "outputs": [],
   "source": [
    "def idx_plbs(arreglo):\n",
    "  \"\"\"\n",
    "  Recibe un arreglo de palabras\n",
    "  Genera un diccionario con los detalles de la palabra\n",
    "  retornando una lista ordenada según relevancia\n",
    "  \"\"\"\n",
    "  largo = len(arreglo)\n",
    "  retorno = list({'word': i, 'value': arreglo[i]} for i in range(largo))\n",
    "  retorno = sorted(retorno, key=lambda x: x['value'], reverse=True)\n",
    "\n",
    "  for i in range(largo):\n",
    "    retorno[i]['id'] = i\n",
    "  return retorno\n",
    "\n",
    "def generar_arrays(array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos para poder dividir\n",
    "  Retorna los arreglos ordenados según relevancia de sus palabras\n",
    "  \"\"\"\n",
    "  return idx_plbs(array_N), idx_plbs(array_L), idx_plbs(array_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iVS2CBb3-YI"
   },
   "outputs": [],
   "source": [
    "def factor_descuento(word, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos y la palabra para la cual\n",
    "  se va a calcular su descuento\n",
    "  Retorna el descuento de la palabra\n",
    "  \"\"\"\n",
    "\n",
    "  fi_L = next(x for x in array_L if x['word'] == word)\n",
    "  fi_R = next(x for x in array_R if x['word'] == word)  \n",
    "  return np.log2(len(array_L) - max(fi_L['id'], fi_R['id']) + 1)\n",
    "\n",
    "\n",
    "def ganancia_palabra(word, array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Recibe los arreglos y la palabra de la que se quiere obtener su ganancia\n",
    "  Retorna la ganancia de la palabra\n",
    "  \"\"\"\n",
    "  \n",
    "  descuento = factor_descuento(word, array_L, array_R)\n",
    "  elemento = next(x for x in array_N if x['word'] == word)\n",
    "  return np.log2(len(array_L) - elemento['id'] + 1)/descuento\n",
    "\n",
    "\n",
    "def ganancias(array_N, array_L, array_R):\n",
    "  \"\"\"\n",
    "  Calcula la ganancia del arreglo\n",
    "  Retorna el arreglo de las ganancias y ordenada según ganancia\n",
    "  \"\"\"\n",
    "  retorno = list()\n",
    "  for word in range(len(array_N)):\n",
    "    gan_actual = ganancia_palabra(word, array_N, array_L, array_R)\n",
    "    retorno.append({'palabra': word, 'ganancia': gan_actual})\n",
    "  \n",
    "  return retorno, sorted(retorno, key=lambda x: x['ganancia'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkS5BLqhGJuf"
   },
   "outputs": [],
   "source": [
    "def MDCG(gan_array):\n",
    "  \"\"\"\n",
    "  Calculo de MDCG según el array que se entregue\n",
    "  Retorna el valor de ganancia\n",
    "  \"\"\"\n",
    "  largo = len(gan_array)\n",
    "  elementos = list(gan_array[i]['ganancia']/np.log2(i+1) for i in range(1, largo))\n",
    "  return gan_array[0]['ganancia'] + sum(elementos)\n",
    "\n",
    "\n",
    "def mNDCG(gan_array, gan_sort):\n",
    "  \"\"\"\n",
    "  Calculo del puntaje a través de los arrays listos\n",
    "  \"\"\"\n",
    "  return MDCG(gan_array)/MDCG(gan_sort)\n",
    "\n",
    "\n",
    "def puntaje(f_N, f_L, f_R):\n",
    "  \"\"\"\n",
    "  Calcula el puntaje de la descomposición NMF actual\n",
    "  Retorna el valor que nos ayuda a decidir\n",
    "  \"\"\"\n",
    "  gan, gan_sort = ganancias(*generar_arrays(f_N, f_L, f_R))\n",
    "  return mNDCG(gan, gan_sort)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42-U4DSMNT_b"
   },
   "outputs": [],
   "source": [
    "def elem_puntaje(A_matrix, L_matrix, R_matrix):\n",
    "  \"\"\"\n",
    "  Calcula la descomposición NMF de A (nodo)\n",
    "  y de sus posibles hijos\n",
    "  Retorna los elementos necesarios para determinar si conviene\n",
    "  \"\"\"\n",
    "\n",
    "  condicion = False\n",
    "  while not condicion:\n",
    "    try:\n",
    "      W, H = calcular_descomposicion(A_matrix)\n",
    "      WL, HL = calcular_descomposicion(L_matrix)\n",
    "      WR, HR = calcular_descomposicion(R_matrix)\n",
    "      condicion = True\n",
    "    except:\n",
    "      condicion = False\n",
    "    else:\n",
    "      if condicion:\n",
    "        return W, H, WL, HL, WR, HR\n",
    "\n",
    "def calculo_puntajes(W, H, WL, HL, WR, HR, i):  \n",
    "  \"\"\"\n",
    "  Calcula el puntaje de los hijos del nodo\n",
    "  a partir de los \n",
    "  \"\"\"\n",
    "  X = W[:, i].copy()\n",
    "\n",
    "  puntaje_N1 = puntaje(X, WL[:, 0], WL[:, 1])\n",
    "  puntaje_N2 = puntaje(X, WR[:, 0], WR[:, 1])\n",
    "\n",
    "  return puntaje_N1, puntaje_N2\n",
    "\n",
    "\n",
    "def puntajes_hijos(A, L, R):\n",
    "  \"\"\"\n",
    "  Genera el calculo del puntaje a partir de los\n",
    "  elementos necesario a partir del nodo\n",
    "  \"\"\"\n",
    "  # W, H, WL, HL, WR, HR = elem_puntaje(A, L, R)\n",
    "  return calculo_puntajes(*elem_puntaje(A, L, R), 0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjhkLjQoaOVE"
   },
   "outputs": [],
   "source": [
    "def agregar_columna(A, columna):\n",
    "  \"\"\"\n",
    "  Agrega columna a la matriz A sin importar su contenido\n",
    "  Retorna la matriz con la columna añadida\n",
    "  \"\"\"\n",
    "  if A is None:\n",
    "    A = np.zeros((len(columna), 1))\n",
    "    A[:, 0] = columna\n",
    "  else:\n",
    "    A = np.column_stack((A,columna))\n",
    "  return A\n",
    "\n",
    "\n",
    "def split_matrix(A_matrix, W, H):\n",
    "  \"\"\"\n",
    "  Separación de la matriz por contenido\n",
    "  Retorna la separación en dos matrices\n",
    "  \"\"\"\n",
    "  m, n = np.shape(A_matrix)\n",
    "\n",
    "  A1, A2 = None, None\n",
    "\n",
    "  for j in range(n):\n",
    "    if H[0][j] > H [1][j]:\n",
    "      A1 = agregar_columna(A1, A_matrix[:, j])\n",
    "    else:\n",
    "      A2 = agregar_columna(A2, A_matrix[:, j])\n",
    "\n",
    "  if A1.shape[1] >= A2.shape[1]:\n",
    "    return A1, A2\n",
    "  return A2, A1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhzFR8xYf5fq"
   },
   "source": [
    "# Parte final\n",
    "\n",
    "Vamos a generar un arreglo que contenga la estructura de nuestro arbol\n",
    "* Será un ejemplo sencillo por lo que usaremos pocos nodos\n",
    "* Usamos un arreglo para los nodos generado\n",
    "* Retornaría este arreglo que describe la estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fbk-HUhf4-I"
   },
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "\n",
    "numero_nodos = 7 # cantidad nodos para crear\n",
    "beta = 1.1 # diferencia de tamaño mínima que habrá entre los nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJgG4CuvgyXS"
   },
   "outputs": [],
   "source": [
    "def seleccionar_nodo(lista_nodos):\n",
    "  \"\"\"\n",
    "  Recibe el arreglo de los nodos de la estructura\n",
    "  Calcula cual nodo es conveniente separar y lo retorna\n",
    "  \"\"\"\n",
    "  if len(lista_nodos) == 1:\n",
    "    return lista_nodos[0]\n",
    "  lista_nodos = sorted(lista_nodos,\n",
    "                       key = lambda i: i['puntaje'],\n",
    "                       reverse=True)\n",
    "  return lista_nodos[1]\n",
    "\n",
    "def menor_puntaje(lista_nodos, puntaje_N2):\n",
    "  \"\"\"\n",
    "  Determina si el puntaje actual es el\n",
    "  menor comparando con todos los nodos\n",
    "  Retorna bool si conviene hacer split a ese nodo\n",
    "  \"\"\"\n",
    "  for elemento in lista_nodos:\n",
    "    if elemento['puntaje'] <= puntaje_N2:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdxgV1Pf1S3p"
   },
   "outputs": [],
   "source": [
    "def palabras_columna(W, i):\n",
    "  \"\"\"\n",
    "  Genera el arreglo de las palabras de la columna i\n",
    "  Retorna arreglo diccionarios con los datos ordenados\n",
    "  \"\"\"\n",
    "\n",
    "  entradas = ['idx', 'value']\n",
    "  distribucion, retorno = W[:, i], list()\n",
    "  for item in enumerate(distribucion):\n",
    "    retorno.append(dict(zip(entradas, item)))\n",
    "  return sorted(retorno, key=lambda i: i['value'], reverse=True)\n",
    "\n",
    "\n",
    "def encontrar_significado(arreglo):\n",
    "  \"\"\"\n",
    "  Recibe el arreglo de indices de palabras\n",
    "  Retorna los elementos con atributo word que es el significado\n",
    "  \"\"\"\n",
    "  for i in range(len(arreglo)):\n",
    "    arreglo[i]['word'] = index_to_word[arreglo[i]['idx'] + 4]\n",
    "  return arreglo\n",
    "\n",
    "def palabras_destacadas(W, cantidad=3):\n",
    "  \"\"\"\n",
    "  Selecciona las palabras más relevantes\n",
    "  de la matriz W\n",
    "  Retorna un arreglo con astas palabras\n",
    "  \"\"\"\n",
    "  n = int(np.round(cantidad/2))+1\n",
    "  retorno = encontrar_significado(palabras_columna(W, 0)[:n])\n",
    "  retorno.extend(encontrar_significado(palabras_columna(W, 1)[:n]))\n",
    "  return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQzkWiA8f2yg"
   },
   "outputs": [],
   "source": [
    "def jerarquizacion(A_matrix):\n",
    "  \"\"\"\n",
    "  Genera la estructura de jerarquía realizando\n",
    "  descomposiciones NMF de forma recursiva\n",
    "  Retorna la estructura \n",
    "  \"\"\"\n",
    "\n",
    "  outliner = None\n",
    "  lista_nodos = list()\n",
    "\n",
    "  primer_nodo = {\n",
    "    'id': 0,\n",
    "    'parent': None,\n",
    "    'matrix': A_matrix,\n",
    "    'puntaje': 1,\n",
    "    'shape': A_matrix.shape,\n",
    "  }\n",
    "\n",
    "  lista_nodos.append(primer_nodo)\n",
    "\n",
    "  for i in range(1, numero_nodos, 2):\n",
    "    M = seleccionar_nodo(lista_nodos)\n",
    "    W, H = calcular_descomposicion(M['matrix'])\n",
    "    M['W'], M['H'] = W, H\n",
    "    N1, N2 = split_matrix(M['matrix'], W, H)\n",
    "    puntaje_N1, puntaje_N2 = puntajes_hijos(M['matrix'], N1, N2)\n",
    "    \n",
    "    N1_nodo = {\n",
    "    'id': i+1,\n",
    "    'parent': M['id'],\n",
    "    'matrix': N1,\n",
    "    'puntaje': puntaje_N1,\n",
    "    'shape': N1.shape,\n",
    "    'hijos': None\n",
    "    }\n",
    "\n",
    "    N2_nodo = {\n",
    "    'id': i+2,\n",
    "    'parent': M['id'],\n",
    "    'matrix': N2,\n",
    "    'puntaje': puntaje_N2,\n",
    "    'shape': N2.shape,\n",
    "    'hijos': None\n",
    "    }\n",
    "\n",
    "    M['hijos'] = [i+1, i+2, ]\n",
    "\n",
    "    lista_nodos.append(N1_nodo)\n",
    "    lista_nodos.append(N2_nodo)\n",
    "\n",
    "  return lista_nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IPf2qvqkVBtc",
    "outputId": "75ee4779-3c94-44ca-9517-42be9ffb01e2"
   },
   "outputs": [],
   "source": [
    "def matriz_W_lista(lista_nodos):\n",
    "  for nodo in lista_nodos:\n",
    "    if 'W' not in nodo.keys():\n",
    "      nodo['W'], nodo['H'] = calcular_descomposicion(nodo['matrix'])\n",
    "  return lista_nodos\n",
    "\n",
    "\n",
    "def limpiar_lista(lista_nodos):\n",
    "  elementos = ['matrix', 'W', 'H']\n",
    "  new_list = [{k: v for k, v in d.items() if k not in elementos} for d in lista_nodos]\n",
    "  return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = jerarquizacion(A_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'parent': None,\n",
       "  'matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'puntaje': 1,\n",
       "  'shape': (100, 173),\n",
       "  'W': array([[0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [2.67695120e-01, 8.11421451e-03],\n",
       "         [2.44972886e-01, 2.47546133e-02],\n",
       "         [2.66903574e-01, 9.29149738e-03],\n",
       "         [2.16641031e-01, 1.37589757e-02],\n",
       "         [2.64164584e-01, 5.86227257e-03],\n",
       "         [2.39068604e-01, 3.41893678e-02],\n",
       "         [2.55799089e-01, 6.39975157e-03],\n",
       "         [6.85056425e-02, 2.80684096e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [2.10544795e-01, 1.04013622e-02],\n",
       "         [1.17455369e-03, 3.75365014e-01],\n",
       "         [1.08191591e-01, 1.57008251e-01],\n",
       "         [2.11190173e-01, 3.14427921e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [2.45723510e-02, 2.21341436e-01],\n",
       "         [1.88214600e-02, 2.68583873e-01],\n",
       "         [1.00804331e-01, 4.43835254e-03],\n",
       "         [1.42338543e-01, 7.23470747e-03],\n",
       "         [1.16226405e-01, 8.32715956e-03],\n",
       "         [1.47224160e-01, 1.59450551e-02],\n",
       "         [1.31251573e-01, 1.91694146e-03],\n",
       "         [1.92685693e-01, 3.91175707e-03],\n",
       "         [1.85247969e-02, 3.46757498e-01],\n",
       "         [1.10061499e-01, 3.83692841e-03],\n",
       "         [1.13162138e-01, 1.98954040e-03],\n",
       "         [5.64913069e-02, 4.52317475e-02],\n",
       "         [1.09255380e-01, 1.75419312e-03],\n",
       "         [1.35880134e-01, 1.94304929e-03],\n",
       "         [2.19294797e-02, 2.16261501e-01],\n",
       "         [1.10713133e-01, 1.85248697e-03],\n",
       "         [9.37506132e-02, 2.45319825e-03],\n",
       "         [2.00481764e-02, 3.55561399e-02],\n",
       "         [4.40242807e-02, 1.21465602e-03],\n",
       "         [4.33016447e-02, 1.76138955e-03],\n",
       "         [4.19112239e-02, 1.34300497e-03],\n",
       "         [1.87415715e-02, 3.27040103e-01],\n",
       "         [1.11266877e-01, 1.26785760e-03],\n",
       "         [8.26384632e-02, 6.23071422e-04],\n",
       "         [1.39829355e-01, 2.69402962e-03],\n",
       "         [1.08716883e-01, 2.12250828e-03],\n",
       "         [2.28352187e-02, 1.45551237e-01],\n",
       "         [9.89463327e-02, 8.93812576e-03],\n",
       "         [9.42336600e-03, 1.17909104e-01],\n",
       "         [1.66819073e-02, 1.82888979e-01],\n",
       "         [3.21240523e-02, 3.14103638e-02],\n",
       "         [1.31656916e-01, 1.39005999e-02],\n",
       "         [9.31624079e-02, 1.75651132e-03],\n",
       "         [4.43162752e-02, 7.92698416e-04],\n",
       "         [7.55477398e-02, 1.14324101e-03],\n",
       "         [8.67703805e-04, 3.47197531e-01],\n",
       "         [3.63781342e-02, 1.12135308e-03],\n",
       "         [9.35631436e-02, 1.05063903e-03],\n",
       "         [7.97949399e-02, 3.94032867e-03],\n",
       "         [6.65863296e-02, 5.05307183e-04],\n",
       "         [6.16938867e-02, 4.50943682e-03],\n",
       "         [2.07666705e-03, 1.42601287e-01],\n",
       "         [9.50461849e-03, 1.68828802e-03],\n",
       "         [2.28614852e-02, 1.16378644e-01],\n",
       "         [7.66005937e-02, 1.48799732e-03],\n",
       "         [1.38072765e-02, 1.64318041e-01],\n",
       "         [6.70572874e-02, 1.60144648e-03],\n",
       "         [1.29378938e-02, 4.69601267e-04],\n",
       "         [2.83938681e-02, 1.80558621e-04],\n",
       "         [9.05467527e-02, 7.61467449e-03],\n",
       "         [1.20242547e-01, 2.91899042e-02],\n",
       "         [4.62543580e-02, 1.98094365e-03],\n",
       "         [8.08117602e-04, 1.19137499e-01],\n",
       "         [1.13240532e-01, 2.71238034e-03],\n",
       "         [1.08217487e-02, 1.28169489e-01],\n",
       "         [6.40748235e-02, 1.28859730e-03],\n",
       "         [8.84337467e-03, 1.17019727e-01],\n",
       "         [6.62494235e-02, 1.78119461e-03],\n",
       "         [4.31900934e-02, 2.58512173e-04],\n",
       "         [4.66160875e-02, 4.72501172e-04],\n",
       "         [9.56366507e-02, 2.39184689e-02],\n",
       "         [8.91709874e-02, 2.41110730e-03],\n",
       "         [7.79488475e-02, 4.46599849e-03],\n",
       "         [1.01406470e-01, 2.87387476e-03],\n",
       "         [1.39228367e-02, 4.66774636e-04],\n",
       "         [2.45080775e-02, 8.99992192e-02],\n",
       "         [1.27256549e-02, 1.39643354e-03],\n",
       "         [5.47376797e-02, 7.98220744e-04],\n",
       "         [4.88897968e-04, 1.92518307e-01],\n",
       "         [1.14328102e-02, 3.16402338e-04],\n",
       "         [1.61171576e-02, 1.00378003e-01],\n",
       "         [1.35156899e-02, 1.46093029e-02],\n",
       "         [5.55250991e-02, 3.77189136e-03],\n",
       "         [4.95382194e-02, 1.79889580e-02],\n",
       "         [6.19381025e-02, 4.14568829e-03],\n",
       "         [3.13261803e-02, 2.80997699e-02],\n",
       "         [3.17994949e-02, 2.29870125e-02],\n",
       "         [6.33328529e-02, 3.56030300e-04],\n",
       "         [4.38868728e-02, 4.55903865e-04],\n",
       "         [6.83574498e-02, 7.48689782e-04],\n",
       "         [2.93383959e-02, 3.39763816e-03],\n",
       "         [2.93016977e-02, 1.46373125e-02]]),\n",
       "  'H': array([[0.00000000e+00, 3.72152202e+00, 7.14740126e-02, 4.17859409e+00,\n",
       "          7.56420288e-02, 0.00000000e+00, 6.64358364e-02, 5.62368582e-04,\n",
       "          1.05450653e-01, 2.66120425e+00, 3.27215917e-02, 0.00000000e+00,\n",
       "          9.59558390e-02, 0.00000000e+00, 2.74360022e-02, 5.23199266e-03,\n",
       "          3.70171292e+00, 7.59069215e-02, 0.00000000e+00, 7.15157136e-02,\n",
       "          1.29460502e-01, 8.99431630e-02, 3.71446115e+00, 9.40037782e-03,\n",
       "          8.72060985e-02, 8.82193950e-02, 5.58471595e+00, 1.08396512e-01,\n",
       "          2.54552201e-02, 4.68592645e+00, 0.00000000e+00, 6.85758704e-02,\n",
       "          1.40351149e-02, 3.31427584e+00, 2.87711789e+00, 1.09946024e-01,\n",
       "          3.06409863e+00, 9.99085502e-02, 3.27603769e+00, 4.32415752e-02,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.71083873e+00, 0.00000000e+00,\n",
       "          1.12356980e-01, 1.00955503e-01, 0.00000000e+00, 9.05557489e-02,\n",
       "          2.79040463e-02, 0.00000000e+00, 2.95259079e+00, 3.92046464e+00,\n",
       "          4.17503173e+00, 3.26070786e+00, 1.05580535e-02, 1.32321712e-01,\n",
       "          5.87914271e+00, 3.87011531e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.26110798e-01, 1.23199220e-01, 3.64171415e+00, 2.16645097e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.50771511e-02, 1.11204130e-01,\n",
       "          8.02426489e-02, 2.78060014e-02, 7.53074279e-02, 3.61702956e+00,\n",
       "          3.01938588e-03, 9.57160059e-02, 1.45676837e-01, 8.83025816e-02,\n",
       "          3.26141538e-02, 6.82476770e-02, 1.53630607e-01, 0.00000000e+00,\n",
       "          1.22365402e-01, 0.00000000e+00, 4.00419265e+00, 2.83353549e-02,\n",
       "          3.08216587e+00, 7.31290503e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "          3.87070134e+00, 1.47717313e-02, 1.35487336e-01, 0.00000000e+00,\n",
       "          2.93396326e-02, 3.92155218e+00, 5.02333833e+00, 0.00000000e+00,\n",
       "          1.45477285e-01, 1.81697603e+00, 1.55421576e-01, 4.05183075e-03,\n",
       "          8.48698382e-02, 3.26718233e+00, 9.97020791e-02, 3.49195954e+00,\n",
       "          9.15963949e-02, 3.91513554e+00, 0.00000000e+00, 3.72223996e+00,\n",
       "          4.32908975e+00, 0.00000000e+00, 5.66552881e-03, 3.17398644e+00,\n",
       "          5.37979848e+00, 0.00000000e+00, 1.46931646e-01, 0.00000000e+00,\n",
       "          3.35450403e-02, 1.94543739e+00, 3.63736593e+00, 2.78442243e-02,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.31708744e+00, 1.17735808e-01,\n",
       "          0.00000000e+00, 1.34509205e-01, 7.76615564e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.73543345e+00, 1.35416359e-01,\n",
       "          3.67165090e+00, 2.69303800e-02, 1.42236636e-01, 9.53949435e-02,\n",
       "          3.37294868e+00, 4.70760817e-02, 1.71306518e+00, 1.34574652e-01,\n",
       "          1.26396963e-02, 0.00000000e+00, 0.00000000e+00, 5.23773155e-02,\n",
       "          1.34084828e-01, 2.97391010e+00, 0.00000000e+00, 7.94078251e-02,\n",
       "          6.82476770e-02, 4.79755567e+00, 8.87833405e-02, 0.00000000e+00,\n",
       "          8.03175066e-02, 3.33160738e+00, 1.48274046e-02, 2.67008632e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.50672401e+00, 0.00000000e+00,\n",
       "          7.77771627e-02, 3.41372359e-02, 1.12755184e-02, 3.05639494e-02,\n",
       "          3.98752325e-03, 4.53642223e-02, 0.00000000e+00, 1.15426224e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.95223550e+00, 0.00000000e+00,\n",
       "          3.19504802e+00],\n",
       "         [2.17133559e+00, 0.00000000e+00, 8.80702057e-03, 0.00000000e+00,\n",
       "          1.69971743e-01, 3.13940277e+00, 2.19383871e-02, 2.13377759e-01,\n",
       "          3.34084079e-02, 0.00000000e+00, 3.16255785e-02, 3.04263685e+00,\n",
       "          1.54683612e-02, 7.86385359e-01, 1.57457247e-01, 7.18947864e-02,\n",
       "          0.00000000e+00, 2.72454586e-02, 2.99293174e+00, 1.38894572e-02,\n",
       "          1.42683541e-02, 2.88636609e-03, 0.00000000e+00, 1.28429408e-01,\n",
       "          9.22976727e-03, 3.47571487e-02, 0.00000000e+00, 2.73338607e-03,\n",
       "          1.24959803e-01, 0.00000000e+00, 2.19664283e+00, 2.76705523e-03,\n",
       "          1.90040036e-01, 0.00000000e+00, 0.00000000e+00, 2.98265112e-02,\n",
       "          0.00000000e+00, 3.35890302e-02, 0.00000000e+00, 1.98838405e-01,\n",
       "          1.81033414e+00, 3.18286572e+00, 0.00000000e+00, 3.25538569e+00,\n",
       "          3.53749763e-03, 7.59485702e-02, 3.64410063e+00, 5.10676463e-03,\n",
       "          1.57601627e-01, 3.36760475e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.57811142e-01, 2.47494600e-02,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.00516169e+00, 1.22880531e+00,\n",
       "          1.36201605e-02, 4.12475733e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "          2.73343651e+00, 2.85218481e+00, 8.30353161e-02, 2.29062839e-02,\n",
       "          1.72374264e-02, 1.78933260e-01, 3.79428334e-03, 0.00000000e+00,\n",
       "          1.54291224e-01, 6.52356836e-03, 3.64277223e-02, 2.25578170e-03,\n",
       "          2.91818780e-02, 1.46153428e-01, 6.91798462e-02, 1.21490959e+00,\n",
       "          1.18764169e-01, 2.86457182e+00, 0.00000000e+00, 6.49478020e-02,\n",
       "          0.00000000e+00, 3.53460809e-02, 2.65958789e+00, 2.70135034e+00,\n",
       "          0.00000000e+00, 1.63060055e-01, 5.40309404e-03, 2.56475208e+00,\n",
       "          1.79819177e-01, 0.00000000e+00, 0.00000000e+00, 2.85328242e+00,\n",
       "          1.98833865e-02, 0.00000000e+00, 2.36735954e-02, 1.05438745e-01,\n",
       "          5.39359997e-02, 0.00000000e+00, 3.94279793e-03, 0.00000000e+00,\n",
       "          4.46245634e-02, 0.00000000e+00, 3.07737935e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.27486832e+00, 1.51380024e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 3.44906040e+00, 3.62173150e-03, 3.54322891e+00,\n",
       "          2.04110202e-01, 0.00000000e+00, 0.00000000e+00, 1.50228697e-01,\n",
       "          2.93888273e+00, 2.56082764e+00, 0.00000000e+00, 1.21174160e-02,\n",
       "          1.41714105e+00, 5.13549310e-02, 1.56063016e-01, 8.01219210e-01,\n",
       "          2.85030314e+00, 9.38516907e-01, 0.00000000e+00, 4.28847972e-02,\n",
       "          0.00000000e+00, 1.11763701e-01, 5.62718489e-02, 2.81141421e-03,\n",
       "          0.00000000e+00, 6.72047648e-03, 0.00000000e+00, 1.92111008e-02,\n",
       "          1.79045491e-01, 3.20183601e+00, 2.28523975e+00, 1.41971695e-01,\n",
       "          2.43505505e-02, 0.00000000e+00, 3.26224296e+00, 8.85530025e-02,\n",
       "          1.46153428e-01, 0.00000000e+00, 6.57337748e-03, 3.60666609e+00,\n",
       "          6.11494457e-02, 0.00000000e+00, 1.11807511e-01, 0.00000000e+00,\n",
       "          7.86140637e-01, 9.00680099e-01, 0.00000000e+00, 8.17067935e-01,\n",
       "          3.71220452e-03, 1.39181134e-01, 9.68947348e-02, 1.65797748e-01,\n",
       "          1.64274872e-01, 3.98598736e-03, 2.85925940e+00, 3.83997412e-02,\n",
       "          3.62061251e+00, 1.08598812e+00, 0.00000000e+00, 3.10779023e+00,\n",
       "          0.00000000e+00]]),\n",
       "  'hijos': [2, 3]},\n",
       " {'id': 2,\n",
       "  'parent': 0,\n",
       "  'matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 1., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'puntaje': 0.4796558978156619,\n",
       "  'shape': (100, 99),\n",
       "  'hijos': None},\n",
       " {'id': 3,\n",
       "  'parent': 0,\n",
       "  'matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'puntaje': 0.55902092638591,\n",
       "  'shape': (100, 74),\n",
       "  'hijos': [4, 5],\n",
       "  'W': array([[0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.08431105],\n",
       "         [0.26705646, 0.        ],\n",
       "         [0.11858344, 0.        ],\n",
       "         [0.22742323, 0.        ],\n",
       "         [0.        , 0.04737089],\n",
       "         [0.23736367, 0.        ],\n",
       "         [0.        , 0.06206006],\n",
       "         [0.01075278, 0.33005855],\n",
       "         [0.        , 0.        ],\n",
       "         [0.1642197 , 0.        ],\n",
       "         [0.20540197, 0.29760032],\n",
       "         [0.39162979, 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.01197806, 0.23634386],\n",
       "         [0.05027429, 0.29638598],\n",
       "         [0.07263534, 0.        ],\n",
       "         [0.10661233, 0.        ],\n",
       "         [0.12879383, 0.        ],\n",
       "         [0.09118186, 0.        ],\n",
       "         [0.        , 0.0098644 ],\n",
       "         [0.02886467, 0.        ],\n",
       "         [0.20615481, 0.23282397],\n",
       "         [0.        , 0.04534099],\n",
       "         [0.        , 0.        ],\n",
       "         [0.1839199 , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.01137024, 0.        ],\n",
       "         [0.02123479, 0.25755997],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.0238461 ],\n",
       "         [0.11967225, 0.        ],\n",
       "         [0.        , 0.0098644 ],\n",
       "         [0.01345277, 0.        ],\n",
       "         [0.01345277, 0.        ],\n",
       "         [0.0223823 , 0.35797842],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.01499052],\n",
       "         [0.        , 0.03354195],\n",
       "         [0.04875348, 0.14721355],\n",
       "         [0.03406985, 0.        ],\n",
       "         [0.00928367, 0.12915027],\n",
       "         [0.04832779, 0.1848438 ],\n",
       "         [0.        , 0.14848322],\n",
       "         [0.1136572 , 0.        ],\n",
       "         [0.        , 0.0238461 ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.03391714, 0.33647588],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.05832057, 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.05933449],\n",
       "         [0.00246145, 0.17064058],\n",
       "         [0.        , 0.02352479],\n",
       "         [0.03730207, 0.14039442],\n",
       "         [0.        , 0.        ],\n",
       "         [0.01078908, 0.17266428],\n",
       "         [0.        , 0.0098644 ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.13241528, 0.        ],\n",
       "         [0.10578872, 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.24951322, 0.        ],\n",
       "         [0.        , 0.02075684],\n",
       "         [0.01301457, 0.15976109],\n",
       "         [0.        , 0.01042653],\n",
       "         [0.01276211, 0.11684415],\n",
       "         [0.        , 0.01121659],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.000645  , 0.03914575],\n",
       "         [0.        , 0.02842513],\n",
       "         [0.09645908, 0.        ],\n",
       "         [0.04351961, 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.029466  , 0.08151609],\n",
       "         [0.00162357, 0.00370747],\n",
       "         [0.        , 0.0098644 ],\n",
       "         [0.00750315, 0.22197433],\n",
       "         [0.        , 0.        ],\n",
       "         [0.00936427, 0.05790285],\n",
       "         [0.11175106, 0.        ],\n",
       "         [0.07175385, 0.        ],\n",
       "         [0.2429516 , 0.        ],\n",
       "         [0.08753766, 0.        ],\n",
       "         [0.40751025, 0.        ],\n",
       "         [0.25588967, 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.        , 0.        ],\n",
       "         [0.0389245 , 0.        ],\n",
       "         [0.03023387, 0.        ]]),\n",
       "  'H': array([[0.93661825, 1.02531436, 1.26789773, 1.40230591, 1.1126063 ,\n",
       "          5.12190358, 0.72684428, 0.98175727, 0.87176719, 0.82608433,\n",
       "          0.78651831, 0.7771546 , 1.07479331, 1.21682282, 0.48895474,\n",
       "          1.2764598 , 0.90794227, 1.14714279, 0.89186896, 1.14135042,\n",
       "          1.00334803, 0.85180027, 0.70754704, 0.76175467, 0.98841834,\n",
       "          0.96386785, 1.33428779, 0.8963203 , 0.95096857, 0.69650982,\n",
       "          0.94991742, 0.52097405, 0.91340377, 0.90262314, 0.77860988,\n",
       "          0.9874864 , 0.91069073, 0.89854797, 0.84825968, 1.10271036,\n",
       "          7.7021089 , 0.81059876, 1.09766569, 1.22686735, 1.42169218,\n",
       "          0.82773697, 0.99051687, 1.07645651, 0.87910453, 0.91901343,\n",
       "          4.86261197, 1.24597033, 0.65141603, 0.61887928, 1.16709909,\n",
       "          1.2612923 , 0.74269927, 1.08733667, 1.22421995, 0.91133003,\n",
       "          0.95096857, 1.2302592 , 1.03028737, 4.86261197, 5.34640786,\n",
       "          4.86261197, 0.79670196, 0.64991667, 1.00976487, 1.27025164,\n",
       "          1.0036201 , 1.3085596 , 6.77421676, 1.31016799],\n",
       "         [0.87257196, 4.65435469, 1.61051801, 3.27143134, 1.94776859,\n",
       "          0.        , 3.63630688, 0.34403354, 2.11944252, 1.96361734,\n",
       "          2.30638062, 1.28535433, 3.5889272 , 4.38338809, 1.04651241,\n",
       "          2.04440286, 2.56092703, 2.67134247, 3.25045543, 2.3057585 ,\n",
       "          2.64316375, 0.92671602, 0.13933834, 2.07963132, 1.70803068,\n",
       "          1.08420018, 3.14478398, 2.46167205, 3.65206522, 0.14160919,\n",
       "          1.72229502, 1.23481002, 1.71646588, 1.75923191, 3.20742243,\n",
       "          1.12900057, 3.82772754, 1.87977968, 1.22587945, 1.95506893,\n",
       "          0.        , 2.7837721 , 2.5647354 , 2.38327075, 3.75574257,\n",
       "          3.23729726, 1.8498275 , 1.05506946, 0.12592986, 2.51632989,\n",
       "          0.        , 1.67218705, 0.02657624, 2.29710621, 2.95382504,\n",
       "          2.23166233, 1.50617713, 3.11019162, 1.88367111, 2.74953729,\n",
       "          3.65206522, 2.39751074, 1.67827363, 0.        , 0.        ,\n",
       "          0.        , 3.0627645 , 1.38125181, 3.48259993, 2.29897998,\n",
       "          1.8391933 , 2.33155099, 0.        , 1.44943147]])},\n",
       " {'id': 4,\n",
       "  'parent': 3,\n",
       "  'matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'puntaje': 0.8330505695096636,\n",
       "  'shape': (100, 60),\n",
       "  'hijos': [6, 7],\n",
       "  'W': array([[0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [2.71083713e-03, 6.58238061e-02],\n",
       "         [6.96234550e-02, 8.01483356e-02],\n",
       "         [1.95563908e-02, 6.25102528e-02],\n",
       "         [5.82376489e-02, 7.20724343e-02],\n",
       "         [0.00000000e+00, 5.70037968e-01],\n",
       "         [5.01946405e-02, 7.39533692e-02],\n",
       "         [4.82571015e-03, 3.73898046e-02],\n",
       "         [2.98418721e-01, 1.08096839e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [3.21297001e-02, 7.64682714e-02],\n",
       "         [3.38320717e-01, 1.23596783e-01],\n",
       "         [1.55332712e-01, 7.83241843e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [2.59898237e-01, 5.24404727e-02],\n",
       "         [2.65246402e-01, 9.96961405e-02],\n",
       "         [1.27995733e-02, 2.63930276e-02],\n",
       "         [1.23271219e-02, 5.09976875e-02],\n",
       "         [3.02740558e-02, 5.07009629e-02],\n",
       "         [6.83164969e-03, 6.97422041e-02],\n",
       "         [2.98221860e-03, 3.88986556e-04],\n",
       "         [3.25814563e-03, 1.05471101e-02],\n",
       "         [3.17360063e-01, 7.16048721e-02],\n",
       "         [1.12357783e-03, 3.47074889e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [9.36579486e-02, 2.01751544e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [7.27716800e-02, 0.00000000e+00],\n",
       "         [2.35503434e-01, 7.84417364e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.86226164e-01],\n",
       "         [1.08442922e-02, 6.66855673e-02],\n",
       "         [2.98221860e-03, 3.88986556e-04],\n",
       "         [0.00000000e+00, 1.34645066e-01],\n",
       "         [0.00000000e+00, 1.34645066e-01],\n",
       "         [3.37075982e-01, 1.18302380e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.63649057e-01],\n",
       "         [0.00000000e+00, 4.18456871e-01],\n",
       "         [1.31591555e-01, 6.67262090e-02],\n",
       "         [4.45533864e-03, 2.31195976e-02],\n",
       "         [1.18641365e-01, 2.72640468e-02],\n",
       "         [1.67258342e-01, 7.10955722e-02],\n",
       "         [5.02211207e-02, 5.71328533e-02],\n",
       "         [2.16378823e-02, 6.54216707e-02],\n",
       "         [0.00000000e+00, 2.86226164e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [3.36827625e-01, 9.57121194e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [6.64795898e-03, 3.47184236e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [1.10484954e-02, 2.45051952e-02],\n",
       "         [1.40482731e-01, 5.81762519e-02],\n",
       "         [0.00000000e+00, 2.83811805e-01],\n",
       "         [1.13193266e-01, 7.27811129e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [1.39293220e-01, 6.85507715e-02],\n",
       "         [2.98221860e-03, 3.88986556e-04],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [3.90400608e-02, 3.84808015e-02],\n",
       "         [4.65808970e-02, 2.62383958e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [1.18854187e-01, 3.76193348e-02],\n",
       "         [1.00669890e-02, 5.69520063e-04],\n",
       "         [1.11647938e-01, 7.93228588e-02],\n",
       "         [4.55606430e-03, 3.10122235e-04],\n",
       "         [1.07487241e-01, 4.70107741e-02],\n",
       "         [1.77343586e-03, 5.24750588e-04],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [4.20152532e-02, 1.25580979e-02],\n",
       "         [4.52064030e-03, 1.85443076e-02],\n",
       "         [3.81936632e-02, 2.39015753e-02],\n",
       "         [6.99699891e-03, 1.06935390e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [8.71172633e-02, 2.67941657e-02],\n",
       "         [0.00000000e+00, 8.54981460e-02],\n",
       "         [2.98221860e-03, 3.88986556e-04],\n",
       "         [2.21654091e-01, 3.89023932e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [7.23749923e-02, 1.23643203e-02],\n",
       "         [3.27209915e-02, 3.19226631e-02],\n",
       "         [1.54614845e-02, 3.06340677e-02],\n",
       "         [2.98221860e-03, 3.88986556e-04],\n",
       "         [4.09220422e-04, 6.31505223e-02],\n",
       "         [1.73610397e-02, 2.98182756e-05],\n",
       "         [5.44246169e-03, 4.89306054e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00],\n",
       "         [4.43532291e-03, 1.41974931e-02],\n",
       "         [1.03250222e-02, 1.25894489e-02]]),\n",
       "  'H': array([[0.00000000e+00, 3.02829976e+00, 2.77227271e+00, 3.57592711e+00,\n",
       "          8.90617756e-01, 3.85690284e+00, 2.58234328e+00, 8.24612695e-01,\n",
       "          2.80469066e+00, 2.23064402e+00, 0.00000000e+00, 2.15204059e+00,\n",
       "          1.95027407e+00, 3.32597670e+00, 3.24791862e+00, 0.00000000e+00,\n",
       "          3.36038840e+00, 2.85427853e+00, 1.92382697e+00, 2.91156912e+00,\n",
       "          3.75524778e+00, 0.00000000e+00, 9.29591433e-01, 3.08973002e+00,\n",
       "          0.00000000e+00, 2.47148738e+00, 0.00000000e+00, 2.75727238e+00,\n",
       "          2.78984472e+00, 1.86231485e+00, 0.00000000e+00, 1.70182106e+00,\n",
       "          3.94522814e+00, 1.23991372e+00, 3.34842591e+00, 2.99818942e+00,\n",
       "          3.21315025e+00, 3.71010256e+00, 1.29077141e+00, 1.54138394e+00,\n",
       "          0.00000000e+00, 3.16039202e+00, 5.16216812e-01, 0.00000000e+00,\n",
       "          2.96932922e+00, 1.88497314e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          3.94432540e+00, 0.00000000e+00, 0.00000000e+00, 3.73330823e+00,\n",
       "          0.00000000e+00, 1.01232403e+00, 1.99788065e+00, 6.07355407e-01,\n",
       "          1.94806977e+00, 2.85009927e+00, 3.42860550e+00, 3.30486758e+00],\n",
       "         [1.14304741e+01, 1.35056648e-01, 3.31156056e-01, 7.56151100e-02,\n",
       "          4.12309928e-01, 3.33553042e-02, 1.41993665e-01, 3.29715803e-01,\n",
       "          1.25818846e-02, 3.57842477e-01, 1.08529773e+01, 2.24962168e-02,\n",
       "          2.40049467e-01, 1.29202247e-01, 1.77300031e-01, 8.56376049e+00,\n",
       "          1.37465537e-01, 1.98767077e-01, 8.59939213e-02, 7.31149870e-02,\n",
       "          2.71898296e-02, 4.20982496e+00, 4.97059647e-01, 1.38448175e-01,\n",
       "          9.91176950e+00, 1.63992298e-01, 4.81074160e+00, 8.21771051e-02,\n",
       "          9.53559849e-02, 3.23072749e-01, 4.17364455e+00, 4.18504692e-01,\n",
       "          2.39157752e-03, 1.76698942e-01, 1.01710795e-01, 1.43737922e-01,\n",
       "          1.52959222e-01, 1.32674108e-01, 5.43358094e-01, 3.49144519e-01,\n",
       "          5.00514779e+00, 1.49878522e-01, 3.53569131e-01, 6.40894581e+00,\n",
       "          2.57669911e-01, 2.71917013e-01, 3.85515823e+00, 9.40461840e+00,\n",
       "          6.17115428e-02, 8.56170182e+00, 9.91176950e+00, 1.33175874e-01,\n",
       "          5.97182994e+00, 3.88050304e-01, 1.04681233e-01, 4.82419679e-01,\n",
       "          2.86311329e-01, 1.02598332e-01, 1.62145227e-01, 1.08228266e-01]])},\n",
       " {'id': 5,\n",
       "  'parent': 3,\n",
       "  'matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'puntaje': 0.5205194192536332,\n",
       "  'shape': (100, 14),\n",
       "  'hijos': None},\n",
       " {'id': 6,\n",
       "  'parent': 4,\n",
       "  'matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "  'puntaje': 0.7929692342684441,\n",
       "  'shape': (100, 46),\n",
       "  'hijos': None},\n",
       " {'id': 7,\n",
       "  'parent': 4,\n",
       "  'matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.]]),\n",
       "  'puntaje': 0.5913591566103968,\n",
       "  'shape': (100, 14),\n",
       "  'hijos': None}]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUj8shzZ9B9J"
   },
   "outputs": [],
   "source": [
    "def obtener_palabras_destacadas(lista_arbol, cantidad=10):\n",
    "  for nodo in lista_arbol:\n",
    "    if nodo['matrix'].shape[1] == 1:\n",
    "      nodo['W'] = nodo['matrix']\n",
    "    elif 'W' not in nodo.keys():\n",
    "      nodo['W'], nodo['H'] = calcular_descomposicion(nodo['matrix'])\n",
    "    nodo['destacadas'] = palabras_destacadas(nodo['W'], cantidad)\n",
    "  return lista_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arbol = obtener_palabras_destacadas(lista_arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OiuTMnkiOfR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'parent': None,\n",
       "  'puntaje': 1,\n",
       "  'shape': (100, 173),\n",
       "  'hijos': [2, 3],\n",
       "  'destacadas': [{'idx': 4, 'value': 0.267695119923541, 'word': 'said'},\n",
       "   {'idx': 6, 'value': 0.26690357388988506, 'word': 'a'},\n",
       "   {'idx': 8, 'value': 0.26416458403383286, 'word': '3'},\n",
       "   {'idx': 10, 'value': 0.2557990888630907, 'word': 'vs'},\n",
       "   {'idx': 5, 'value': 0.24497288603817555, 'word': 'and'},\n",
       "   {'idx': 9, 'value': 0.2390686035007416, 'word': 'for'},\n",
       "   {'idx': 14, 'value': 0.37536501371379677, 'word': '000'},\n",
       "   {'idx': 53, 'value': 0.34719753069690296, 'word': 'have'},\n",
       "   {'idx': 26, 'value': 0.34675749809830314, 'word': 'be'},\n",
       "   {'idx': 39, 'value': 0.32704010308148046, 'word': 'as'},\n",
       "   {'idx': 11, 'value': 0.28068409596962246, 'word': 'dlrs'},\n",
       "   {'idx': 19, 'value': 0.26858387319648946, 'word': 'is'}]},\n",
       " {'id': 2,\n",
       "  'parent': 0,\n",
       "  'puntaje': 0.4796558978156619,\n",
       "  'shape': (100, 99),\n",
       "  'hijos': None,\n",
       "  'destacadas': [{'idx': 21, 'value': 0.4153839312022661, 'word': 'its'},\n",
       "   {'idx': 7, 'value': 0.30569444843724386, 'word': 'mln'},\n",
       "   {'idx': 28, 'value': 0.2723814808087748, 'word': '2'},\n",
       "   {'idx': 27, 'value': 0.2621988896604828, 'word': 'with'},\n",
       "   {'idx': 42, 'value': 0.24362265095004135, 'word': 'loss'},\n",
       "   {'idx': 43, 'value': 0.21625064224698945, 'word': '4'},\n",
       "   {'idx': 25, 'value': 0.3288579660233686, 'word': 'year'},\n",
       "   {'idx': 23, 'value': 0.2553927675623756, 'word': 'by'},\n",
       "   {'idx': 22, 'value': 0.21354944789244426, 'word': 'cts'},\n",
       "   {'idx': 11, 'value': 0.21348968608118749, 'word': 'dlrs'},\n",
       "   {'idx': 33, 'value': 0.2023203799687351, 'word': 'u'},\n",
       "   {'idx': 81, 'value': 0.1968354301634153, 'word': 'been'}]},\n",
       " {'id': 3,\n",
       "  'parent': 0,\n",
       "  'puntaje': 0.55902092638591,\n",
       "  'shape': (100, 74),\n",
       "  'hijos': [4, 5],\n",
       "  'destacadas': [{'idx': 93, 'value': 0.4075102507749466, 'word': 'than'},\n",
       "   {'idx': 15, 'value': 0.3916297949961742, 'word': '1'},\n",
       "   {'idx': 5, 'value': 0.2670564647512595, 'word': 'and'},\n",
       "   {'idx': 94, 'value': 0.25588967137871377, 'word': 'quarter'},\n",
       "   {'idx': 70, 'value': 0.24951321583173766, 'word': 'profit'},\n",
       "   {'idx': 91, 'value': 0.2429516036808037, 'word': 'more'},\n",
       "   {'idx': 39, 'value': 0.35797841544612674, 'word': 'as'},\n",
       "   {'idx': 53, 'value': 0.33647588359151726, 'word': 'have'},\n",
       "   {'idx': 11, 'value': 0.33005855472800866, 'word': 'dlrs'},\n",
       "   {'idx': 14, 'value': 0.2976003186455262, 'word': '000'},\n",
       "   {'idx': 19, 'value': 0.2963859754872543, 'word': 'is'},\n",
       "   {'idx': 32, 'value': 0.25755996642324885, 'word': 'he'}]},\n",
       " {'id': 4,\n",
       "  'parent': 3,\n",
       "  'puntaje': 0.8330505695096636,\n",
       "  'shape': (100, 60),\n",
       "  'hijos': [6, 7],\n",
       "  'destacadas': [{'idx': 14, 'value': 0.33832071700440625, 'word': '000'},\n",
       "   {'idx': 39, 'value': 0.33707598170660685, 'word': 'as'},\n",
       "   {'idx': 53, 'value': 0.3368276247855394, 'word': 'have'},\n",
       "   {'idx': 26, 'value': 0.3173600633366448, 'word': 'be'},\n",
       "   {'idx': 11, 'value': 0.29841872063884844, 'word': 'dlrs'},\n",
       "   {'idx': 19, 'value': 0.265246402033254, 'word': 'is'},\n",
       "   {'idx': 8, 'value': 0.5700379684460535, 'word': '3'},\n",
       "   {'idx': 43, 'value': 0.41845687108507273, 'word': '4'},\n",
       "   {'idx': 34, 'value': 0.2862261635806167, 'word': 's'},\n",
       "   {'idx': 50, 'value': 0.2862261635806167, 'word': 'last'},\n",
       "   {'idx': 60, 'value': 0.2838118048654368, 'word': 'had'},\n",
       "   {'idx': 42, 'value': 0.16364905744222014, 'word': 'loss'}]},\n",
       " {'id': 5,\n",
       "  'parent': 3,\n",
       "  'puntaje': 0.5205194192536332,\n",
       "  'shape': (100, 14),\n",
       "  'hijos': None,\n",
       "  'destacadas': [{'idx': 93, 'value': 0.5877425487535857, 'word': 'than'},\n",
       "   {'idx': 14, 'value': 0.46770893649270234, 'word': '000'},\n",
       "   {'idx': 26, 'value': 0.46770893649270234, 'word': 'be'},\n",
       "   {'idx': 94, 'value': 0.3545564403400935, 'word': 'quarter'},\n",
       "   {'idx': 83, 'value': 0.20368628725084464, 'word': 'prices'},\n",
       "   {'idx': 91, 'value': 0.14736228774129126, 'word': 'more'},\n",
       "   {'idx': 39, 'value': 0.4709613367565016, 'word': 'as'},\n",
       "   {'idx': 86, 'value': 0.4709613367565016, 'word': 'per'},\n",
       "   {'idx': 32, 'value': 0.44692359146814764, 'word': 'he'},\n",
       "   {'idx': 63, 'value': 0.4289522008763191, 'word': 'share'},\n",
       "   {'idx': 14, 'value': 0.20234756779565416, 'word': '000'},\n",
       "   {'idx': 26, 'value': 0.20234756779565416, 'word': 'be'}]},\n",
       " {'id': 6,\n",
       "  'parent': 4,\n",
       "  'puntaje': 0.7929692342684441,\n",
       "  'shape': (100, 46),\n",
       "  'hijos': None,\n",
       "  'destacadas': [{'idx': 46, 'value': 0.42606848328174685, 'word': 'which'},\n",
       "   {'idx': 74, 'value': 0.39227297710321707, 'word': 'two'},\n",
       "   {'idx': 14, 'value': 0.2593699078360623, 'word': '000'},\n",
       "   {'idx': 11, 'value': 0.24783895796398603, 'word': 'dlrs'},\n",
       "   {'idx': 53, 'value': 0.24701709636545857, 'word': 'have'},\n",
       "   {'idx': 39, 'value': 0.24306734496437252, 'word': 'as'},\n",
       "   {'idx': 67, 'value': 0.4684492655130972, 'word': 'inc'},\n",
       "   {'idx': 13, 'value': 0.4574152303179783, 'word': 'reuter'},\n",
       "   {'idx': 80, 'value': 0.44132143731149825, 'word': 'up'},\n",
       "   {'idx': 89, 'value': 0.44088526997660316, 'word': 'april'},\n",
       "   {'idx': 93, 'value': 0.29055546612741984, 'word': 'than'},\n",
       "   {'idx': 90, 'value': 0.16954982026917773, 'word': 'march'}]},\n",
       " {'id': 7,\n",
       "  'parent': 4,\n",
       "  'puntaje': 0.5913591566103968,\n",
       "  'shape': (100, 14),\n",
       "  'hijos': None,\n",
       "  'destacadas': [{'idx': 5, 'value': 0.34904870755822204, 'word': 'and'},\n",
       "   {'idx': 35, 'value': 0.3128932333759638, 'word': 'net'},\n",
       "   {'idx': 7, 'value': 0.30943509112768025, 'word': 'mln'},\n",
       "   {'idx': 47, 'value': 0.3030060953768146, 'word': 'but'},\n",
       "   {'idx': 44, 'value': 0.29358165915564555, 'word': '1986'},\n",
       "   {'idx': 59, 'value': 0.26782206173751233, 'word': '8'},\n",
       "   {'idx': 26, 'value': 0.327904849487003, 'word': 'be'},\n",
       "   {'idx': 48, 'value': 0.27401517620952554, 'word': 'this'},\n",
       "   {'idx': 18, 'value': 0.26619949111234925, 'word': 'from'},\n",
       "   {'idx': 21, 'value': 0.2558166886599807, 'word': 'its'},\n",
       "   {'idx': 22, 'value': 0.2549088398576994, 'word': 'cts'},\n",
       "   {'idx': 8, 'value': 0.24915067575006652, 'word': '3'}]}]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar_lista(lista_arbol)\n",
    "lista_arbol = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6HMGSCyKq6r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "cosa= np.array([[1],[2],[3]])\n",
    "print(cosa.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reuters.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
